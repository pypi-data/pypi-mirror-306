from dataclasses import dataclass
from typing import List, Dict, Any, Optional

from gen_ai_hub.orchestration.models.message import Message


@dataclass
class LLMUsage:
    """
    Represents the token usage statistics for an LLM (Large Language Model) operation.

    Attributes:
        completion_tokens: The number of tokens generated by the model in the response.
        prompt_tokens: The number of tokens in the input prompt.
        total_tokens: The total number of tokens used, including both prompt and completion tokens.
    """

    completion_tokens: int
    prompt_tokens: int
    total_tokens: int


@dataclass
class LLMChoice:
    """
    Represents an individual choice or response generated by the LLM.

    Attributes:
        index: The index of this particular choice in the list of possible choices.
        message: The message object containing the role and content of the response.
        finish_reason: The reason why the model stopped generating tokens.
    """

    index: int
    message: Message
    finish_reason: str


@dataclass
class LLMResult:
    """
    Represents the complete result from an LLM operation, including the generated choices and usage statistics.

    Attributes:
        id: The unique identifier for this LLM operation.
        object: The type of object returned (typically "chat.completion").
        created: The timestamp when this result was created.
        model: The name or identifier of the model used for generating the result.
        choices: A list of possible choices generated by the LLM.
        usage: The token usage statistics for this operation.
    """

    id: str
    object: str
    created: int
    model: str
    choices: List[LLMChoice]
    usage: LLMUsage


@dataclass
class GenericModuleResult:
    """
    Represents a generic module result in the orchestration process.

    Attributes:
        message: A message or description generated by the module.
        data: Additional data relevant to the module result.
    """

    message: str
    data: Optional[Dict[str, Any]]


@dataclass
class ModuleResults:
    """
    Represents the results of various modules used in processing an orchestration request,
    including templating, LLM operations, and optional filtering.

    Attributes:
        templating: A list of messages that define the conversation's context or template.
        llm: The result from the LLM operation.
        input_filtering: The result of any input filtering, if applicable.
        output_filtering: The result of any output filtering, if applicable.
        input_masking: The result of input masking, if applicable.
        output_unmasking: The result of output unmasking, if applicable.
    """

    templating: List[Message]
    llm: LLMResult
    input_filtering: Optional[GenericModuleResult] = None
    output_filtering: Optional[GenericModuleResult] = None
    input_masking: Optional[GenericModuleResult] = None
    output_unmasking: Optional[List[LLMChoice]] = None


@dataclass
class OrchestrationResponse:
    """
    Represents the complete response from an orchestration process,
    including the request ID, module results, and orchestration result.

    Attributes:
        request_id: The unique identifier for the request being processed.
        module_results: The results from the various modules involved in processing the request.
        orchestration_result: The final result from the orchestration, typically mirroring the LLM result.
    """

    request_id: str
    module_results: ModuleResults
    orchestration_result: LLMResult
