{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salient Predictions 2023-24 Ski-Cast Retrospective\n",
    "\n",
    "In November, Salient predicted snow accumulation at 90 IKON and Epic resorts. Imagine you were deciding at the time to book a March 1 spring break ski trip.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<requests.sessions.Session at 0x7fbddd18b190>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "try:\n",
    "    import salientsdk as sk\n",
    "except ModuleNotFoundError as e:\n",
    "    if os.path.exists(\"../salientsdk\"):\n",
    "        sys.path.append(os.path.abspath(\"..\"))\n",
    "        import salientsdk as sk\n",
    "    else:\n",
    "        raise ModuleNotFoundError(\"Install salient SDK with: pip install salientsdk\")\n",
    "\n",
    "force = False\n",
    "(start_date, end_date) = (\"2023-12-01\", \"2024-04-30\")\n",
    "vac_date = \"2024-03-01\"  # Date of theoretical vacation\n",
    "sk.set_file_destination(\"ski_example\")\n",
    "sk.login(\"username\", \"password\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "resorts = {\n",
    "    \"japan\": pd.DataFrame(\n",
    "        [\n",
    "            {\"lon\": 137.861, \"lat\": 36.690, \"name\": \"Hakuba\"},  # epic\n",
    "            {\"lon\": 140.687, \"lat\": 42.824, \"name\": \"Rusutsu\"},  # epic\n",
    "            {\"lon\": 140.685, \"lat\": 42.824, \"name\": \"Niseko\"},  # ikon\n",
    "            {\"lon\": 140.685, \"lat\": 42.824, \"name\": \"Lotte Arai\"},  # ikon\n",
    "            # Tazawako indy\n",
    "            # Okunakayama\n",
    "        ]\n",
    "    ),\n",
    "    \"alps\": pd.DataFrame(\n",
    "        [\n",
    "            {\"lon\": 6.8632749, \"lat\": 45.924065, \"name\": \"Chamonix\"},  # ikon\n",
    "            {\"lon\": 7.7522747, \"lat\": 46.0222204, \"name\": \"Zermatt\"},  # ikon\n",
    "            {\"lon\": 8.5916293, \"lat\": 46.6324621, \"name\": \"Andermatt-Sedrun\"},  # epic\n",
    "            {\"lon\": 12.3925407, \"lat\": 47.4492375, \"name\": \"Kitzbuhel\"},  # ikon\n",
    "        ]\n",
    "    ),\n",
    "    \"pnw\": pd.DataFrame(\n",
    "        [\n",
    "            {\"lon\": -123.204545, \"lat\": 49.396018, \"name\": \"Cypress\"},  # ikon\n",
    "            {\"lon\": -121.6781891, \"lat\": 44.0024701, \"name\": \"Bachelor\"},  # ikon\n",
    "            {\"lon\": -121.0890197, \"lat\": 47.7448119, \"name\": \"Stevens Pass\"},  # epic\n",
    "            {\"lon\": -122.9486474, \"lat\": 50.1149639, \"name\": \"Whistler\"},  # epic\n",
    "            {\"lon\": -121.4747533, \"lat\": 46.9352963, \"name\": \"Crystal Mtn\"},  # ikon\n",
    "            {\"lon\": -121.4257485, \"lat\": 47.4442426, \"name\": \"Alpental\"},  # ikon\n",
    "            {\"lon\": -121.4164161, \"lat\": 47.4245711, \"name\": \"Snoqualmie\"},  # ikon\n",
    "        ]\n",
    "    ),\n",
    "    \"rockies\": pd.DataFrame(\n",
    "        [\n",
    "            # The four Aspen resorts all perform similarly.  Combine into one:\n",
    "            # {\"lon\": -106.9490961, \"lat\": 39.2083984, \"name\": \"Aspen Snowmass\"},\n",
    "            # {\"lon\": -106.8610687, \"lat\": 39.2058029, \"name\": \"Buttermilk\"},\n",
    "            # {\"lon\": -106.8553613, \"lat\": 39.1824124, \"name\": \"Aspen Highlands\"},\n",
    "            {\"lon\": -106.818227, \"lat\": 39.1862601, \"name\": \"Aspen Mtn\"},  # ikon\n",
    "            {\"lon\": -106.8045169, \"lat\": 40.4571991, \"name\": \"Steamboat\"},  # ikon\n",
    "            # Beaver Creek and Vail perform similarly and are right next to each other\n",
    "            # {\"lon\": -106.5167109, \"lat\": 39.6042863, \"name\": \"Beaver Creek\"}, # epic\n",
    "            {\"lon\": -106.3549717, \"lat\": 39.6061444, \"name\": \"Vail\"},  # epic\n",
    "            {\"lon\": -106.1516265, \"lat\": 39.501419, \"name\": \"Copper\"},  # ikon\n",
    "            {\"lon\": -106.0676088, \"lat\": 39.4808351, \"name\": \"Breckenridge\"},  # epic\n",
    "            {\"lon\": -105.9437656, \"lat\": 39.6075962, \"name\": \"Keystone\"},  # epic\n",
    "            {\"lon\": -105.8719397, \"lat\": 39.6425118, \"name\": \"A-Basin\"},  # ikon\n",
    "            {\"lon\": -105.762488, \"lat\": 39.8868392, \"name\": \"Winter Park\"},  # ikon\n",
    "            {\"lon\": -105.5826786, \"lat\": 39.9372203, \"name\": \"Eldora\"},  # ikon\n",
    "        ]\n",
    "    ),\n",
    "    \"new_england\": pd.DataFrame(\n",
    "        [\n",
    "            {\"lon\": -72.9278443, \"lat\": 43.0906207, \"name\": \"Stratton\"},  # ikon\n",
    "            {\"lon\": -72.9204014, \"lat\": 42.9602444, \"name\": \"Mt Snow\"},  # epic\n",
    "            {\"lon\": -72.8944139, \"lat\": 44.1359019, \"name\": \"Sugarbush\"},  # ikon\n",
    "            # {\"lon\": -72.842512, \"lat\": 43.6621499, \"name\": \"Pico\"}, # ikon near Killington\n",
    "            {\"lon\": -72.7967531, \"lat\": 43.6262922, \"name\": \"Killington\"},  # ikon\n",
    "            {\"lon\": -72.7814124, \"lat\": 44.5303066, \"name\": \"Stowe\"},  # epic\n",
    "            {\"lon\": -72.7170416, \"lat\": 43.4018257, \"name\": \"Okemo\"},  # epic\n",
    "            {\"lon\": -72.08014, \"lat\": 43.331889, \"name\": \"Sunapee\"},  # epic\n",
    "            {\"lon\": -71.8655176, \"lat\": 43.0198715, \"name\": \"Crotched\"},  # epic\n",
    "            {\"lon\": -71.6336041, \"lat\": 44.0563456, \"name\": \"Loon\"},  # ikon\n",
    "            {\"lon\": -71.2393036, \"lat\": 44.2640724, \"name\": \"Wildcat\"},  # epic\n",
    "            {\"lon\": -71.229443, \"lat\": 44.082771, \"name\": \"Attitash\"},  # epic\n",
    "            {\"lon\": -70.8568727, \"lat\": 44.4734182, \"name\": \"Sunday River\"},  # ikon\n",
    "            {\"lon\": -70.3085109, \"lat\": 45.0541811, \"name\": \"Sugarloaf\"},  # ikon\n",
    "        ]\n",
    "    ),\n",
    "    \"europe\": pd.DataFrame(\n",
    "        [\n",
    "            {\"lon\": 1.4707674, \"lat\": 42.5729217, \"name\": \"Arinsal\"},  # ikon\n",
    "            {\"lon\": 1.499825, \"lat\": 42.6317345, \"name\": \"Ordino Arcal√≠s\"},  # ikon\n",
    "            {\"lon\": 1.6462281, \"lat\": 42.5783833, \"name\": \"Grandvalira\"},  # ikon\n",
    "            {\"lon\": 11.6520936, \"lat\": 46.5739752, \"name\": \"Dolomiti\"},  # ikon\n",
    "        ]\n",
    "    ),\n",
    "    \"na_west\": pd.DataFrame(\n",
    "        [\n",
    "            {\"lon\": -120.2483913, \"lat\": 39.1906091, \"name\": \"Palisades Tahoe\"},  # ikon\n",
    "            {\"lon\": -120.1210934, \"lat\": 39.2745678, \"name\": \"Northstar\"},  # epic\n",
    "            {\"lon\": -120.0651665, \"lat\": 38.6847514, \"name\": \"Kirkwood\"},  # epic\n",
    "            {\"lon\": -119.9428424, \"lat\": 38.9569241, \"name\": \"Heavenly\"},  # epic\n",
    "            {\"lon\": -119.8859331, \"lat\": 50.8844311, \"name\": \"Sun Peaks\"},  # ikon\n",
    "            {\"lon\": -119.0906293, \"lat\": 37.7679169, \"name\": \"June\"},  # ikon\n",
    "            {\"lon\": -119.0267806, \"lat\": 37.6510972, \"name\": \"Mammoth\"},  # ikon\n",
    "            {\"lon\": -118.1630779, \"lat\": 50.9583858, \"name\": \"Revelstoke\"},  # ikon\n",
    "            {\"lon\": -117.8194705, \"lat\": 49.1024147, \"name\": \"RED\"},  # ikon\n",
    "            {\"lon\": -117.036177, \"lat\": 34.2248821, \"name\": \"Snow Valley\"},  # ikon\n",
    "            {\"lon\": -116.8892717, \"lat\": 34.2364081, \"name\": \"Snow Summit\"},  # ikon\n",
    "            {\"lon\": -116.8608572, \"lat\": 34.2276766, \"name\": \"Bear Mtn\"},  # ikon\n",
    "            {\"lon\": -116.6227441, \"lat\": 48.3679757, \"name\": \"Schweitzer\"},  # ikon\n",
    "            {\"lon\": -116.2380671, \"lat\": 50.4602801, \"name\": \"Panorama\"},  # ikon\n",
    "            {\"lon\": -116.1621717, \"lat\": 51.4419206, \"name\": \"Lake Louise\"},  # ikon\n",
    "            {\"lon\": -115.7840699, \"lat\": 51.0780997, \"name\": \"Banff\"},  # ikon\n",
    "            {\"lon\": -115.5982699, \"lat\": 51.2037624, \"name\": \"Norquay\"},  # ikon\n",
    "            {\"lon\": -115.5707632, \"lat\": 51.1751675, \"name\": \"SkiBig3\"},  # ikon\n",
    "            {\"lon\": -114.3542874, \"lat\": 43.6949128, \"name\": \"Sun Valley\"},  # ikon\n",
    "            {\"lon\": -114.3461537, \"lat\": 43.6820566, \"name\": \"Dollar Mtn\"},  # ikon\n",
    "            {\"lon\": -111.8571529, \"lat\": 41.2161404, \"name\": \"Snowbasin\"},  # ikon\n",
    "            # The four Cottonwood Canyon resorts all perform similarly.  Combine:\n",
    "            # {\"lon\": -111.6563885, \"lat\": 40.5810814, \"name\": \"Snowbird\"},\n",
    "            {\"lon\": -111.6385807, \"lat\": 40.5884218, \"name\": \"Alta\"},  # ikon\n",
    "            # {\"lon\": -111.591885, \"lat\": 40.619852, \"name\": \"Solitude\"},\n",
    "            # {\"lon\": -111.583187, \"lat\": 40.598019, \"name\": \"Brighton\"},\n",
    "            {\"lon\": -111.5079947, \"lat\": 40.6514199, \"name\": \"Park City\"},  # epic\n",
    "            {\"lon\": -111.478306, \"lat\": 40.63738, \"name\": \"Deer Valley\"},  # ikon\n",
    "            {\"lon\": -111.4012076, \"lat\": 45.2857289, \"name\": \"Big Sky\"},  # ikon\n",
    "            {\"lon\": -110.8279183, \"lat\": 43.5875453, \"name\": \"Jackson Hole\"},  # ikon\n",
    "            {\"lon\": -106.9878231, \"lat\": 38.8697146, \"name\": \"Crested Butte\"},  # ikon\n",
    "            {\"lon\": -105.4545, \"lat\": 36.5959999, \"name\": \"Taos\"},  # ikon\n",
    "        ]\n",
    "    ),\n",
    "    \"na_east\": pd.DataFrame(\n",
    "        [\n",
    "            {\"lon\": -94.9707416, \"lat\": 39.4673048, \"name\": \"Snow Creek\"},  # epic- Kansas City\n",
    "            {\"lon\": -92.7878062, \"lat\": 44.8576608, \"name\": \"Afton\"},  # epic - Minneapolis\n",
    "            {\"lon\": -90.6506898, \"lat\": 38.5353168, \"name\": \"Hidden Valley\"},  # epic\n",
    "            {\"lon\": -88.1876602, \"lat\": 42.4989548, \"name\": \"Wilmot\"},  # epic\n",
    "            {\"lon\": -86.5122305, \"lat\": 38.5555868, \"name\": \"Paoli\"},  # epic\n",
    "            {\"lon\": -84.930067, \"lat\": 45.162884, \"name\": \"Boyne\"},  # ikon\n",
    "            # {\"lon\": -84.926535, \"lat\": 45.4647239, \"name\": \"Boyne Highlands\"},  # ikon\n",
    "            {\"lon\": -83.8115217, \"lat\": 42.54083, \"name\": \"Mt. Brighton\"},  # epic\n",
    "            {\"lon\": -83.6777778, \"lat\": 40.3180556, \"name\": \"Mad River\"},  # epic\n",
    "            {\"lon\": -81.5632108, \"lat\": 41.2640987, \"name\": \"Boston Mills\"},  # epic\n",
    "            {\"lon\": -81.259745, \"lat\": 41.52687, \"name\": \"Alpine Valley\"},  # epic\n",
    "            {\"lon\": -80.3122216, \"lat\": 44.5037818, \"name\": \"Blue Mtn\"},  # ikon\n",
    "            {\"lon\": -79.9960444, \"lat\": 38.4118566, \"name\": \"Snowshoe\"},  # ikon\n",
    "            {\"lon\": -79.2977032, \"lat\": 40.0229768, \"name\": \"7 Springs\"},  # epic\n",
    "            {\"lon\": -79.2581204, \"lat\": 40.058031, \"name\": \"Hidden Valley 2\"},  # epic\n",
    "            {\"lon\": -79.1657908, \"lat\": 40.1638728, \"name\": \"Laurel\"},  # epic\n",
    "            {\"lon\": -77.9333126, \"lat\": 39.7417652, \"name\": \"Whitetail\"},  # epic\n",
    "            {\"lon\": -77.375459, \"lat\": 39.76366, \"name\": \"Liberty\"},  # epic\n",
    "            {\"lon\": -76.9275492, \"lat\": 40.1094506, \"name\": \"Roundtop\"},  # epic\n",
    "            {\"lon\": -75.6563315, \"lat\": 41.1091686, \"name\": \"Jack Frost\"},  # epic\n",
    "            {\"lon\": -75.601282, \"lat\": 41.050189, \"name\": \"Big Boulder\"},  # epic\n",
    "            {\"lon\": -74.5852526, \"lat\": 46.2096417, \"name\": \"Tremblant\"},  # ikon\n",
    "            {\"lon\": -74.2567116, \"lat\": 42.2937298, \"name\": \"Windham\"},  # ikon\n",
    "            {\"lon\": -74.2246402, \"lat\": 42.2028811, \"name\": \"Hunter\"},  # epic\n",
    "        ]\n",
    "    ),\n",
    "}\n",
    "\n",
    "# Assign a color to each region for later plotting purposes, using\n",
    "# Tol's colorblind-friendly \"vibrant\" palette.\n",
    "# https://cran.r-project.org/web/packages/khroma/vignettes/tol.html\n",
    "colors = {\n",
    "    \"japan\": \"#004488\",  # blue\n",
    "    \"alps\": \"#33BBEE\",  # cyan\n",
    "    \"pnw\": \"#009988\",  # teal\n",
    "    \"rockies\": \"#CC3311\",  # red\n",
    "    \"new_england\": \"#DDAA33\",  # yellow\n",
    "    \"europe\": \"#555555\",  # dark grey\n",
    "    \"na_west\": \"#666666\",  # grey\n",
    "    \"na_east\": \"#777777\",  # light grey\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "location file: ['ski_resorts_japan.csv', 'ski_resorts_alps.csv', 'ski_resorts_pnw.csv', 'ski_resorts_rockies.csv', 'ski_resorts_new_england.csv', 'ski_resorts_europe.csv', 'ski_resorts_na_west.csv', 'ski_resorts_na_east.csv']\n"
     ]
    }
   ],
   "source": [
    "geo_files = {\n",
    "    region: sk.upload_location_file(\n",
    "        lats=geo[\"lat\"],\n",
    "        lons=geo[\"lon\"],\n",
    "        names=geo[\"name\"],\n",
    "        geoname=f\"ski_resorts_{region}\",\n",
    "        force=force,\n",
    "    )\n",
    "    for region, geo in resorts.items()\n",
    "}\n",
    "\n",
    "# We will later use a Location object to query the Salient API\n",
    "# The functions are capable of handling multiple location files,\n",
    "# so we can pass a vector here.\n",
    "ski_locs = sk.Location(location_file=list(geo_files.values()))\n",
    "print(ski_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acquire the data\n",
    "\n",
    "For each of the ski resorts, we will get the daily forecast of temperature and precipitation as of the beginning of the season. Then we will also get the historical observed conditions, calculate snowfall, and merge them into a single dataset for later analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daily Downscale Forecast\n",
    "\n",
    "In contrast to the probabilistic `forecast_timeseries` function, `downscale` samples historical analogs from the forecast distribution to create ensemble timeseries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no need to vectorize the \"variables\" argument, since that is natively\n",
    "# supported by the downscale function.  We will vectorize over location_files.\n",
    "vars = \"temp,precip\"\n",
    "fcst_files = sk.downscale(\n",
    "    loc=ski_locs,\n",
    "    variables=vars,\n",
    "    members=51,\n",
    "    date=\"2023-11-15\",\n",
    "    force=force,\n",
    ")\n",
    "\n",
    "# Because we are requesting multiple location_files, fcst_files is a\n",
    "# table with multiple downscale files.  Let's combine all of them:\n",
    "fcst = xr.open_mfdataset(\n",
    "    fcst_files[\"file_name\"].values,\n",
    "    concat_dim=\"location\",\n",
    "    combine=\"nested\",\n",
    ")\n",
    "# Align the data to the ski season:\n",
    "fcst = fcst.sel(forecast_day=slice(start_date, end_date))\n",
    "\n",
    "# We use scientific units for precip like mm day-1\n",
    "# Let's make this more readable for plotting purposes:\n",
    "fcst[\"precip\"].attrs[\"units\"] = \"mm/day\"\n",
    "\n",
    "# rename \"forecast_day\" to \"time\" to match the output from data_timeseries\n",
    "fcst = fcst.rename({\"forecast_day\": \"time\"})\n",
    "\n",
    "# Remove things we don't need:\n",
    "fcst = fcst.drop_vars([\"temp_clim\", \"precip_clim\", \"temp_anom\", \"precip_anom\"])\n",
    "\n",
    "fcst = fcst.compute()\n",
    "\n",
    "print(fcst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Historical Data\n",
    "\n",
    "The `data_timeseries` function will load the historical daily ERA5 timeseries, which we can later compare to the `downscale` timeseries ensembles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 218kB\n",
      "Dimensions:        (time: 141, location: 92)\n",
      "Coordinates:\n",
      "  * time           (time) datetime64[ns] 1kB 2023-12-01 ... 2024-04-19\n",
      "  * location       (location) object 736B '7 Springs' 'A-Basin' ... 'Zermatt'\n",
      "    lat            (location) float64 736B 40.02 39.64 44.86 ... 39.89 46.02\n",
      "    lon            (location) float64 736B -79.3 -105.9 -92.79 ... -105.8 7.752\n",
      "    location_file  (location) object 736B 'ski_resorts_na_east.csv' ... 'ski_...\n",
      "    region         (location) <U11 4kB 'na_east' 'rockies' ... 'rockies' 'alps'\n",
      "    color          (location) <U7 3kB '#777777' '#CC3311' ... '#33BBEE'\n",
      "Data variables:\n",
      "    temp           (time, location) float64 104kB 6.131 -10.16 ... -2.506 -3.933\n",
      "    precip         (time, location) float64 104kB 7.096 2.444 ... 7.548 6.581\n"
     ]
    }
   ],
   "source": [
    "# Get historical observed performance for each ski resort\n",
    "hist_files = sk.data_timeseries(\n",
    "    loc=ski_locs,\n",
    "    variable=vars,\n",
    "    field=\"vals\",\n",
    "    start=start_date,\n",
    "    end=end_date,\n",
    "    frequency=\"daily\",\n",
    "    force=force,\n",
    ")\n",
    "\n",
    "# Assemble each historical file into a single xarray dataset\n",
    "hist = sk.load_multihistory(hist_files)\n",
    "\n",
    "# Assign a color to each region for plotting purposes later\n",
    "prefix = \"ski_resorts_\"\n",
    "suffix = \".csv\"\n",
    "region = [x.replace(prefix, \"\").replace(suffix, \"\") for x in hist[\"location_file\"].values]\n",
    "regcol = [colors[reg] for reg in region]\n",
    "hist = hist.assign_coords(region=(\"location\", region), color=(\"location\", regcol))\n",
    "\n",
    "print(hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Snow Water Equivalent\n",
    "\n",
    "The `calc_swe` function builds on the `snow17` model to calculate the snow water equivalent (SWE) at each location and for each ensemble. It requires that the dataset input has data values `precip` and `temp`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast -----\n",
      "Data variables:\n",
      "    temp     (ensemble, time, location) float32 3MB 1.453 -1.982 ... 15.7 15.62\n",
      "    precip   (ensemble, time, location) float32 3MB 4.384 1.429 ... 0.1029\n",
      "    swe      (ensemble, time, location) float64 6MB 0.5607 1.429 ... 0.0 0.0\n",
      "    swe_avg  (location) float64 736B 211.4 130.0 130.0 ... 130.7 38.33 26.93\n",
      "Historical ---\n",
      "Data variables:\n",
      "    temp     (time, location) float64 104kB 6.131 -10.16 ... -2.506 -3.933\n",
      "    precip   (time, location) float64 104kB 7.096 2.444 0.0 ... 1.5 7.548 6.581\n",
      "    swe      (time, location) float64 104kB 0.0 2.444 0.0 ... 0.0 248.8 425.3\n",
      "    swe_avg  (location) float64 736B 6.142 125.1 4.767 ... 5.589 120.3 270.9\n"
     ]
    }
   ],
   "source": [
    "if \"swe\" not in fcst:\n",
    "    fcst[\"swe\"] = sk.hydro.calc_swe(fcst, \"time\")\n",
    "\n",
    "if \"swe\" not in hist:\n",
    "    hist[\"swe\"] = sk.hydro.calc_swe(hist, \"time\")\n",
    "\n",
    "fcst[\"swe_avg\"] = fcst[\"swe\"].mean([\"ensemble\", \"time\"])\n",
    "hist[\"swe_avg\"] = hist[\"swe\"].mean([\"time\"])\n",
    "\n",
    "print(\"Forecast -----\")\n",
    "print(fcst.data_vars)\n",
    "print(\"Historical ---\")\n",
    "print(hist.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge\n",
    "\n",
    "Combine the historical and forecast datasets into a single dataset so that we can make sure they are aligned by `location`.\n",
    "\n",
    "We don't want to highlight resorts with below-average snowfall, so let's sort the dataset and cut out the bottom half.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data variables:\n",
      "    temp_fcst     (ensemble, time, location) float32 1MB -6.447 -2.447 ... 5.885\n",
      "    precip_fcst   (ensemble, time, location) float32 1MB 0.0 0.5713 ... 6.178\n",
      "    swe_fcst      (ensemble, time, location) float64 3MB 0.0 0.5713 ... 252.4\n",
      "    swe_avg_fcst  (location) float64 368B 47.5 113.5 176.1 ... 288.4 558.1 372.5\n",
      "    temp_hist     (time, location) float64 56kB -5.678 2.13 0.1348 ... nan nan\n",
      "    precip_hist   (time, location) float64 56kB 3.058 0.1531 20.88 ... nan nan\n",
      "    swe_hist      (time, location) float64 56kB 3.058 0.0 15.55 ... nan nan nan\n",
      "    swe_avg_hist  (location) float64 368B 67.46 71.13 74.33 ... 401.3 407.9\n"
     ]
    }
   ],
   "source": [
    "met = xr.merge(\n",
    "    [\n",
    "        fcst.rename({var: f\"{var}_fcst\" for var in fcst.data_vars}),\n",
    "        hist.rename({var: f\"{var}_hist\" for var in hist.data_vars}),\n",
    "    ]\n",
    ")\n",
    "# We're interested in the resorts that have better-than-average snowfall:\n",
    "met = met.sortby(\"swe_avg_hist\")\n",
    "met = met.isel(location=slice(len(met.location) // 2, None))\n",
    "\n",
    "print(met.data_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 63kB\n",
      "Dimensions:        (location: 46, ensemble: 51)\n",
      "Coordinates:\n",
      "    time           datetime64[ns] 8B 2024-03-01\n",
      "  * location       (location) object 368B 'Taos' 'Attitash' ... 'Stevens Pass'\n",
      "    analog         (location, ensemble) datetime64[ns] 19kB 1978-03-17 ... 19...\n",
      "    lat            (location) float64 368B 36.6 44.08 47.45 ... 50.11 47.74\n",
      "    lon            (location) float64 368B -105.5 -71.23 12.39 ... -122.9 -121.1\n",
      "    forecast_date  datetime64[ns] 8B 2023-11-15\n",
      "    location_file  (location) object 368B 'ski_resorts_na_west.csv' ... 'ski_...\n",
      "    region         (location) <U11 2kB 'na_west' 'new_england' ... 'pnw' 'pnw'\n",
      "    color          (location) <U7 1kB '#666666' '#DDAA33' ... '#009988'\n",
      "Dimensions without coordinates: ensemble\n",
      "Data variables:\n",
      "    temp_fcst      (ensemble, location) float32 9kB -2.386 -3.989 ... -1.401\n",
      "    precip_fcst    (ensemble, location) float32 9kB 0.0 6.77 ... 0.0 0.02302\n",
      "    swe_fcst       (ensemble, location) float64 19kB 116.6 247.7 ... 642.3 428.9\n",
      "    swe_avg_fcst   (location) float64 368B 47.5 113.5 176.1 ... 558.1 372.5\n",
      "    temp_hist      (location) float64 368B -0.7092 -9.795 ... -5.671 -4.266\n",
      "    precip_hist    (location) float64 368B 0.0 0.000586 5.503 ... 14.28 7.391\n",
      "    swe_hist       (location) float64 368B 98.61 128.1 78.07 ... 518.9 585.2\n",
      "    swe_avg_hist   (location) float64 368B 67.46 71.13 74.33 ... 401.3 407.9\n"
     ]
    }
   ],
   "source": [
    "def plot_boxes(\n",
    "    fcst: xr.DataArray,\n",
    "    hist: xr.DataArray = None,\n",
    "    title: str = \"\",\n",
    "    legend_loc: str = \"center right\",\n",
    "    ax=None,\n",
    "):\n",
    "    \"\"\"Plot predictions and observed values as a box-and-whisker plot.\"\"\"\n",
    "    # extract a table of seasonal averages per location\n",
    "    # if the length of the time dimension is >1, take the mean.  Otherwise, we're good.\n",
    "    if \"time\" in fcst.dims:\n",
    "        xlab = \"Season Mean\"\n",
    "        avg = fcst.mean(dim=\"time\")\n",
    "    else:\n",
    "        xlab = str(np.datetime_as_string(fcst.time.values, unit=\"D\"))\n",
    "        avg = fcst\n",
    "    avg = avg.to_dataframe(dim_order=[\"location\", \"ensemble\"])\n",
    "    avg = avg[fcst.name].unstack(level=0).to_numpy()\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5, 10))  # Create a new figure if no axis is provided\n",
    "\n",
    "    plt_box = ax.boxplot(\n",
    "        avg,\n",
    "        showfliers=False,\n",
    "        vert=False,\n",
    "        labels=fcst.location.values,\n",
    "        patch_artist=True,\n",
    "        meanline=True,\n",
    "        showmeans=True,\n",
    "        meanprops=dict(linewidth=1, color=\"white\"),\n",
    "        medianprops=dict(linewidth=0, color=\"gray\", alpha=0),\n",
    "        whiskerprops=dict(linewidth=0.7, color=\"gray\"),\n",
    "        capprops=dict(linewidth=0.7, color=\"gray\"),\n",
    "        boxprops=dict(linewidth=0.7, color=\"gray\"),\n",
    "    )\n",
    "    [patch.set_facecolor(color) for patch, color in zip(plt_box[\"boxes\"], fcst.color.values)]\n",
    "    ax.set_xlabel(f\"{xlab} {fcst.long_name} ({fcst.units})\")\n",
    "    ax.set_title(title)\n",
    "    legend_names = [\"japan\", \"alps\", \"pnw\", \"rockies\", \"new_england\"]\n",
    "    legend_handles = plt_box[\"boxes\"][: len(legend_names)]\n",
    "\n",
    "    if isinstance(hist, xr.DataArray):\n",
    "        if \"time\" in hist.dims and hist.dims[\"time\"] > 1:\n",
    "            obs = hist.mean(dim=\"time\")\n",
    "        else:\n",
    "            obs = hist\n",
    "\n",
    "        plt_hist = ax.plot(obs, np.arange(len(hist.location)) + 1, color=\"black\", linewidth=2)\n",
    "        legend_handles += [plt_hist[0]]\n",
    "        legend_names += [\"Observed\"]\n",
    "    elif isinstance(hist, float):\n",
    "        # plot a grey dotted vertical line at the value of hist\n",
    "        plt_hist = ax.axvline(hist, color=\"grey\", linestyle=\"--\", linewidth=1)\n",
    "    else:\n",
    "        plt_hist = None\n",
    "\n",
    "    if legend_loc != \"none\":\n",
    "        leg = ax.legend(legend_handles, legend_names, loc=legend_loc)\n",
    "        for patch, reg in zip(leg.get_patches(), legend_names):\n",
    "            patch.set_facecolor(colors[reg])\n",
    "\n",
    "\n",
    "vac_met = met.sel(time=vac_date)\n",
    "print(vac_met)\n",
    "vac_met = vac_met.sortby(\"swe_hist\")\n",
    "\n",
    "\n",
    "plot_boxes(vac_met[\"swe_fcst\"], vac_met[\"swe_hist\"], \"Snow Forecast by Location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drivers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_diff = met[\"temp_fcst\"] - met[\"temp_hist\"]\n",
    "temp_diff.name = \"temp_diff\"\n",
    "temp_diff.attrs[\"long_name\"] = \"Temperature Error\"\n",
    "temp_diff.attrs[\"units\"] = \"C\"\n",
    "\n",
    "precip_diff = met[\"precip_fcst\"] - met[\"precip_hist\"]\n",
    "precip_diff.name = \"precip_diff\"\n",
    "precip_diff.attrs[\"long_name\"] = \"Precipitation Error\"\n",
    "precip_diff.attrs[\"units\"] = \"mm\"\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 10))\n",
    "plot_boxes(temp_diff, 0.0, title=\"Temp Error by Location\", legend_loc=\"center left\", ax=ax1)\n",
    "plot_boxes(precip_diff, 0.0, title=\"Precip Error by Location\", legend_loc=\"none\", ax=ax2)\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensemble Variation at 4 Resorts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_names = [\"Whistler\", \"Andermatt-Sedrun\", \"Copper\", \"Sugarloaf\"]\n",
    "\n",
    "\n",
    "def plot_ensembles(loc, var=\"temp\", title=False):\n",
    "    \"\"\"Show ensemble values for a given variable.\"\"\"\n",
    "    x_val = \"time\"\n",
    "    var_fcst = f\"{var}_fcst\"\n",
    "    var_hist = f\"{var}_hist\"\n",
    "    val_hist = loc[var_hist].rolling(time=3, center=True).mean()\n",
    "\n",
    "    loc_plt = loc[var_fcst].plot.line(x=x_val, color=\"grey\", alpha=0.1, add_legend=False)\n",
    "    avg_plt = (\n",
    "        loc[var_fcst]\n",
    "        .mean(dim=\"ensemble\", keep_attrs=True)\n",
    "        .plot.line(x=x_val, color=loc[\"color\"].values.tolist(), linewidth=2, add_legend=False)\n",
    "    )\n",
    "    obs_plt = val_hist.plot.line(\n",
    "        x=x_val, color=\"black\", linestyle=\"-\", linewidth=2, add_legend=False\n",
    "    )\n",
    "    vac_time = loc.sel(time=vac_date).time.values\n",
    "    plt.axvline(vac_time, color=\"k\", linestyle=\"--\")\n",
    "\n",
    "    plt.title(loc[\"location\"].values if title else \"\")\n",
    "    plt.xlabel(\"\")\n",
    "\n",
    "\n",
    "(fig, axs) = plt.subplots(\n",
    "    nrows=3,\n",
    "    ncols=len(focus_names),\n",
    "    sharex=True,\n",
    "    sharey=\"row\",\n",
    "    figsize=(5 * len(focus_names), 15),\n",
    ")\n",
    "\n",
    "for idx in range(len(focus_names)):\n",
    "    loc = met.sel(location=focus_names[idx])\n",
    "    plt.sca(axs[0, idx])\n",
    "    plot_ensembles(loc, \"swe\", title=True)\n",
    "    plt.sca(axs[1, idx])\n",
    "    plot_ensembles(loc, \"temp\")\n",
    "    plt.axhline(0, color=\"k\", linestyle=\"--\")\n",
    "    plt.sca(axs[2, idx])\n",
    "    plot_ensembles(loc, \"precip\")\n",
    "    plt.gca().set_ylim((0, 40))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 ('salient')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "51f8f0b1da789c29b6dfdfd0d04fb138f3b7f54f0cf7fdaf39807db9fc45e326"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
