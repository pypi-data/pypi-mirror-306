Metadata-Version: 2.3
Name: neat-llm
Version: 0.1.1a10
Summary: Neat is a simpler and more intuitive abstraction for quickly working with llms. Easily create tool-calling agents, generate structured output, and easily switch between a wide range of models providers, simplifying the process of building and protoyping llm applications.
License-File: LICENSE
Keywords: ai,language-model,llm,llm-agents
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.8
Requires-Dist: beautifulsoup4
Requires-Dist: docstring-parser==0.16
Requires-Dist: duckduckgo-search
Requires-Dist: litellm>=1.44.14
Requires-Dist: loguru
Requires-Dist: numpydoc
Requires-Dist: pydantic-settings>=2.0.0
Requires-Dist: pydantic>=2.8.0
Requires-Dist: rich==13.8.0
Description-Content-Type: text/markdown

# neat-llm

A simpler abstraction for working with Large Language Models (LLMs).

## Features

- **Unified Interface**: Work with multiple LLM providers (OpenAI, Anthropic, Cohere, Mistral) through a single, consistent API.
- **Prompt Management**: Create, version, and reuse prompts easily. (In development)
- **Tool Integration**: Seamlessly integrate custom tools and functions for LLMs to use.
- **Structured Outputs**: Define and validate structured outputs using Pydantic models.
- **Type Safety**: Leverage Python's type hinting for a safer development experience.
- **Flexible Configuration**: Easy-to-use configuration management with environment variable support.
- **Conversation Mode**: Engage in multi-turn dialogues with your agent.
- **Flexible Message Formatting**: Use both traditional message dictionary format and neat's helper methods for message construction.

**Note**: Prompt versioning and database features are currently under development and may change in future releases.

## Installation

```bash
pip install neat-llm
```

## API Key Setup

To use neat-llm with various LLM providers, set up your API keys using one of these methods:

1. Create a `.env` file in your project root:

   ```
   OPENAI_API_KEY=your_openai_api_key
   ANTHROPIC_API_KEY=your_anthropic_api_key
   COHERE_API_KEY=your_cohere_api_key
   MISTRAL_API_KEY=your_mistral_api_key
   ```

2. Set API keys programmatically:

   ```python
   from neat import neat_config

   neat_config.openai_api_key = "your_openai_api_key"
   neat_config.anthropic_api_key = "your_anthropic_api_key"
   neat_config.cohere_api_key = "your_cohere_api_key"
   neat_config.mistral_api_key = "your_mistral_api_key"
   ```

Replace `your_*_api_key` with your actual API keys from the respective providers.

## Quick Start

neat-llm offers two ways to construct messages: helper methods for convenience, and traditional message dictionary format for those who prefer it. Both approaches are fully supported.

### Using Helper Methods

Here's an example using neat's helper methods:

```python
from neat import Neat

neat = Neat()

@neat.lm()
def generate_story(theme: str, length: int):
    return [
        neat.system("You are a creative story writer."),
        neat.user(f"Write a {length}-word story about {theme}."),
    ]

def main():
    story = generate_story("time travel", 100)
    print(f"Generated Story:\n{story}")

if __name__ == "__main__":
    main()
```

### Using Traditional Dictionary Format

Here's the same example using the traditional dictionary format:

```python
from neat import Neat

neat = Neat()

@neat.lm()
def generate_story(theme: str, length: int):
    return [
        {"role": "system", "content": "You are a creative story writer."},
        {"role": "user", "content": f"Write a {length}-word story about {theme}."},
    ]

def main():
    story = generate_story("time travel", 100)
    print(f"Generated Story:\n{story}")

if __name__ == "__main__":
    main()
```

Both approaches are equivalent and will work seamlessly with neat-llm.

## Advanced Usage

### Custom Tools

Currently, neat-llm does not support decorating methods and classes directly. As a workaround, you can use a function wrapper to define your custom tools.

```python
from neat import Neat
from pydantic import BaseModel, Field
import random

neat = Neat()

# Custom Tools

Currently, neat-llm does not support decorating methods and classes directly. As a workaround, you can use a function wrapper to define your custom tools.

```python
from neat import Neat
import random

neat = Neat()

# Custom tool to get weather information
def get_weather(location: str) -> dict:
    """Fetch current weather information for a given location."""
    # Simulating weather data for demonstration
    temp = round(random.uniform(-5, 35), 1)
    conditions = random.choice(["Sunny", "Cloudy", "Rainy", "Windy", "Snowy"])
    return {"temperature": temp, "conditions": conditions}

# Custom tool to recommend clothing based on weather
def recommend_clothing(weather: dict) -> dict:
    """Recommend clothing based on weather conditions."""
    if weather["temperature"] < 10:
        return {"top": "Warm coat", "bottom": "Thick pants", "accessories": "Scarf and gloves"}
    elif 10 <= weather["temperature"] < 20:
        return {"top": "Light jacket", "bottom": "Jeans", "accessories": "Light scarf"}
    else:
        return {"top": "T-shirt", "bottom": "Shorts", "accessories": "Sunglasses"}

# Register the functions as tools
neat.add_tool(get_weather)
neat.add_tool(recommend_clothing)
# Register the function as a tool
neat.add_tool(recommend_clothing)

@neat.lm(tools=[get_weather, recommend_clothing])
def assistant():
    return [
        neat.system("You are a helpful weather and fashion assistant. Use the get_weather tool to check the weather for specific locations, and the recommend_clothing tool to suggest appropriate outfits based on the weather."),
        neat.user("What's the weather like in Paris today, and what should I wear?"),
    ]

def main():
    conversation = assistant()
    print(f"Weather and Fashion Assistant:\n{conversation}")
if __name__ == "__main__":
    main()
```

### Structured Outputs

Use Pydantic models to define and validate structured outputs.

```python
from neat import Neat
from pydantic import BaseModel, Field

neat = Neat()

# Use the docstring and field descriptors to provide the llm hints as to what the output should look like
class MovieRecommendation(BaseModel):
    """Represents a movie recommendation with details."""
    title: str = Field(..., description="The title of the recommended movie")
    year: int = Field(..., description="The release year of the movie")
    genre: str = Field(..., description="The primary genre of the movie")
    reason: str = Field(..., description="A brief explanation for why this movie is recommended")

@neat.lm(response_model=MovieRecommendation)
def recommend_movie(preferences: str):
    return [
        neat.system("You are a movie recommendation expert. Provide recommendations based on user preferences."),
        neat.user(f"Recommend a movie based on these preferences: {preferences}"),
    ]

def main():
    preferences = "I like sci-fi movies with mind-bending plots and strong character development"
    movie = recommend_movie(preferences)
    print(f"Movie Recommendation: Title: {movie.title} ({movie.year}), Genre: {movie.genre}, Reason: {movie.reason}")
if __name__ == "__main__":
    main()
```

### Conversation Mode

Engage in interactive dialogues with your AI assistant.

```python
from neat import Neat

neat = Neat()

@neat.lm(conversation=True)
def chat_with_ai():
    return [
        neat.system("You are a friendly and knowledgeable AI assistant. Engage in a conversation with the user, answering their questions and providing helpful information."),
        neat.user("Hello! I'd like to chat about various topics. What shall we discuss?"),
    ]

def main():
    chat_with_ai()  # This will start an interactive conversation

if __name__ == "__main__":
    main()
```

In conversation mode, you'll see a rich console interface with color-coded messages and formatted text. To exit the conversation, type "exit" or "quit".

## License

This project is licensed under the MIT License - see the LICENSE file for details.
