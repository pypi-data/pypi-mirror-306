{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import datasets as nlp_datasets\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from cappr import openai\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\", \"..\"))\n",
    "from utils import display_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is a tough cookie and does a good job demonstrating that zero-shot\n",
    "classification is not very appropriate for more expert-level tasks. I wouldn't recommend\n",
    "using CAPPr or even GPT-3+ in cases like these. You should instead train a model so that\n",
    "it picks up the subtle correlations in the training data&mdash;subtelties which are hard\n",
    "to verbalize in a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## When hitting the OpenAI endpoints, we'll log any server errors\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    handlers=[logging.StreamHandler(stream=sys.stdout)],\n",
    "                    format='%(asctime)s :: %(name)s :: %(levelname)s :: '\n",
    "                           '%(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-04 18:11:12,608 :: datasets.builder :: WARNING :: Found cached dataset raft (C:/Users/kushd/.cache/huggingface/datasets/ought___raft/one_stop_english/1.1.0/79c4de1312c1e3730043f7db07179c914f48403101f7124e2fe336f6f54d9f84)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(nlp_datasets\n",
    "                  .load_dataset('ought/raft', 'one_stop_english', split='train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For 85 years, it was just a grey blob on class...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>He had the tastes of a typical millionaire. He...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Moroccan city of Ouarzazate is used to big...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SeaWorld has suffered an 84% collapse in profi...</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There are worse things to do in life than stro...</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  ID  Label\n",
       "0  For 85 years, it was just a grey blob on class...   0      3\n",
       "1  He had the tastes of a typical millionaire. He...   1      1\n",
       "2  The Moroccan city of Ouarzazate is used to big...   2      1\n",
       "3  SeaWorld has suffered an 84% collapse in profi...   3      3\n",
       "4  There are worse things to do in life than stro...   4      2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt(article: str, num_paragraphs: int=3, paragraph_delimeter: str='\\n') -> str:\n",
    "    article_truncated = (paragraph_delimeter\n",
    "                         .join(article\n",
    "                               .split(paragraph_delimeter)\n",
    "                               [:num_paragraphs]))\n",
    "    return ('An article was rewritten to suit three levels of adult English as Second '\n",
    "            'Language (ESL) learners: elementary, intermediate, and advanced. Predict '\n",
    "            'the level that this article was written in.\\n\\n'\n",
    "            f'Article: {article_truncated}\\n'\n",
    "             'Label:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['prompt'] = [prompt(article) for article in df['Article']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_7b53e_row0_col0, #T_7b53e_row0_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_7b53e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_7b53e_level0_col0\" class=\"col_heading level0 col0\" >prompt</th>\n",
       "      <th id=\"T_7b53e_level0_col1\" class=\"col_heading level0 col1\" >Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_7b53e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_7b53e_row0_col0\" class=\"data row0 col0\" >An article was rewritten to suit three levels of adult English as Second Language (ESL) learners: elementary, intermediate, and advanced. Predict the level that this article was written in.\n",
       "\n",
       "Article: For 85 years, it was just a grey blob on classroom maps of the solar system. But, on 15 July, Pluto was seen in high resolution for the first time. The images show dramatic mountain ranges made from solid water ice as big as the Alps or the Rockies.\n",
       "The extraordinary images of the former ninth planet and its large moon, Charon, were sent back 4bn miles to Earth from the New Horizons spacecraft. They are the climax of a mission that has been quietly underway for nearly ten years.\n",
       "Alan Stern, the mission’s principal investigator, said “New Horizons is returning amazing results. The data look absolutely gorgeous, and Pluto and Charon are just mind-blowing.”\n",
       "Label:</td>\n",
       "      <td id=\"T_7b53e_row0_col1\" class=\"data row0 col1\" >3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1a4ffc8ce20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_df(df, columns=['prompt', 'Label'], num_rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36, 0.4 , 0.24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior = (df['Label']\n",
    "         .value_counts(normalize=True)\n",
    "         .sort_index()\n",
    "         .to_numpy())\n",
    "prior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3297dd17a868405780b8cb475102b1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "log-probs:   0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## $0.77\n",
    "pred_probs = (openai.classify\n",
    "              .predict_proba(df['prompt'].tolist(),\n",
    "                             completions=('advanced', 'elementary', 'intermediate'),\n",
    "                             model='text-davinci-003',\n",
    "                             prior=prior,\n",
    "                             ask_if_ok=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24510551741673023"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(df['Label']-1, pred_probs.argmax(axis=1), average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_probs.argmax(axis=1) == df['Label']-1).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not better than the majority classifier, ouch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 2, 0, 0, 0,\n",
       "       2, 0, 0, 0, 2, 0, 2, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2,\n",
       "       0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs.argmax(axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly miscalibrated lol"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cappr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
