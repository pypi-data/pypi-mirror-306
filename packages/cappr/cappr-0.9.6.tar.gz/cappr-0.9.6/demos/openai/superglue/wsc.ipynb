{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Description**: demonstrates that the zero-shot text classification method [described\n",
                "here](https://stats.stackexchange.com/q/601159/337906) works well on the [Winograd\n",
                "Schema Challenge (WSC)](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html). It's\n",
                "one of the [SuperGLUE tasks](https://super.gluebenchmark.com/tasks) in which labels have\n",
                "multiple tokens, in some sense. Surprisingly `text-curie-001` is 84% accurate.\n",
                "\n",
                "☣️ **Contamination notice** ☣️: Some of the WSC examples were included in GPT-3's\n",
                "training data! So `gpt-3.5-turbo-instruct` and `text-curie-001` were very likely trained\n",
                "on WSC. The authors [studied this\n",
                "contamination](https://arxiv.org/pdf/2005.14165.pdf#page=31&zoom=100,96,89) and \"found a\n",
                "2.6% decrease in performance on the clean subset\".\n",
                "\n",
                "**Estimated run time**: ~30 sec.\n",
                "\n",
                "**Environment**: See the [Setup section in the\n",
                "README](https://github.com/kddubey/cappr/#installation).\n",
                "\n",
                "**Other**: You have to have an OpenAI API key stored in the environment variable\n",
                "`OPENAI_API_KEY`. [Sign up here](https://openai.com/api/). This notebook will manually\n",
                "ask you to give the go-ahead before incurring any costs. It'll cost ya about\n",
                "<span>$</span>0.04."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "[Load data](#load-data)\n",
                "\n",
                "[Write prompt](#write-prompt)\n",
                "\n",
                "[Run model](#run-model)\n",
                "\n",
                "[Score](#score)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "import logging\n",
                "import os\n",
                "import sys\n",
                "\n",
                "import datasets as nlp_datasets\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from cappr import Example\n",
                "from cappr import openai\n",
                "from cappr.utils import _batch\n",
                "\n",
                "sys.path.insert(1, os.path.join(sys.path[0], \"..\", \"..\"))\n",
                "from utils import display_df, remove_suffix"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# When hitting the OpenAI endpoints, we'll log any server errors\n",
                "logging.basicConfig(\n",
                "    level=logging.INFO,\n",
                "    handlers=[logging.StreamHandler(stream=sys.stdout)],\n",
                "    format=\"%(asctime)s :: %(name)s :: %(levelname)s :: \" \"%(message)s\",\n",
                ")\n",
                "logger = logging.getLogger(__name__)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Load data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Given a passage with a (marked) ambiguous pronoun, the classification problem is to pick 1 of 2 alternatives which the pronoun refers to. \n",
                "\n",
                "See the [example on the website](https://cs.nyu.edu/~davise/papers/WinogradSchemas/WS.html). It's pretty cool."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The test set labels are hidden, so I'll score this zero-shot classifier on the 273 examples in the `wsc273` subset of the challenge."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "df: pd.DataFrame = (nlp_datasets\n",
                "                    .load_dataset('winograd_wsc', 'wsc273') ## TODO: idk what the subsets are\n",
                "                    ['test'] ## only available split\n",
                "                    .data.to_pandas())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "273"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>text</th>\n",
                            "      <th>pronoun</th>\n",
                            "      <th>pronoun_loc</th>\n",
                            "      <th>quote</th>\n",
                            "      <th>quote_loc</th>\n",
                            "      <th>options</th>\n",
                            "      <th>label</th>\n",
                            "      <th>source</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>The city councilmen refused the demonstrators ...</td>\n",
                            "      <td>they</td>\n",
                            "      <td>63</td>\n",
                            "      <td>they feared violence</td>\n",
                            "      <td>63</td>\n",
                            "      <td>[The city councilmen, The demonstrators]</td>\n",
                            "      <td>0</td>\n",
                            "      <td>(Winograd 1972)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>The city councilmen refused the demonstrators ...</td>\n",
                            "      <td>they</td>\n",
                            "      <td>63</td>\n",
                            "      <td>they advocated violence</td>\n",
                            "      <td>63</td>\n",
                            "      <td>[The city councilmen, The demonstrators]</td>\n",
                            "      <td>1</td>\n",
                            "      <td>(Winograd 1972)</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>The trophy doesn't fit into the brown suitcase...</td>\n",
                            "      <td>it</td>\n",
                            "      <td>55</td>\n",
                            "      <td>it is too large</td>\n",
                            "      <td>55</td>\n",
                            "      <td>[the trophy, the suitcase]</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Hector Levesque</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>The trophy doesn't fit into the brown suitcase...</td>\n",
                            "      <td>it</td>\n",
                            "      <td>55</td>\n",
                            "      <td>it is too small</td>\n",
                            "      <td>55</td>\n",
                            "      <td>[the trophy, the suitcase]</td>\n",
                            "      <td>1</td>\n",
                            "      <td>Hector Levesque</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>Joan made sure to thank Susan for all the help...</td>\n",
                            "      <td>she</td>\n",
                            "      <td>47</td>\n",
                            "      <td>she had received</td>\n",
                            "      <td>47</td>\n",
                            "      <td>[Joan, Susan]</td>\n",
                            "      <td>0</td>\n",
                            "      <td>Hector Levesque</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "                                                text pronoun  pronoun_loc  \\\n",
                            "0  The city councilmen refused the demonstrators ...    they           63   \n",
                            "1  The city councilmen refused the demonstrators ...    they           63   \n",
                            "2  The trophy doesn't fit into the brown suitcase...      it           55   \n",
                            "3  The trophy doesn't fit into the brown suitcase...      it           55   \n",
                            "4  Joan made sure to thank Susan for all the help...     she           47   \n",
                            "\n",
                            "                     quote  quote_loc  \\\n",
                            "0     they feared violence         63   \n",
                            "1  they advocated violence         63   \n",
                            "2          it is too large         55   \n",
                            "3          it is too small         55   \n",
                            "4         she had received         47   \n",
                            "\n",
                            "                                    options  label           source  \n",
                            "0  [The city councilmen, The demonstrators]      0  (Winograd 1972)  \n",
                            "1  [The city councilmen, The demonstrators]      1  (Winograd 1972)  \n",
                            "2                [the trophy, the suitcase]      0  Hector Levesque  \n",
                            "3                [the trophy, the suitcase]      1  Hector Levesque  \n",
                            "4                             [Joan, Susan]      0  Hector Levesque  "
                        ]
                    },
                    "execution_count": 5,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.head()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Write prompt"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The method we'll use is described in [this paper](https://arxiv.org/abs/1806.02847)<sup>1</sup>. See Table 1. We'll do the \"partial\" method b/c the authors demonstrate that it performs better. The motivation there is identical to the motivation behind this package. In fact, section 3.4 of the [GPT-3 paper](https://arxiv.org/abs/2005.14165)<sup>2</sup> doesn't actually use sampling for WSC! It uses the same partial method. I guess my algorithm isn't so novel after all, heh.\n",
                "\n",
                "1. Trinh, Trieu H., and Quoc V. Le. \"A simple method for commonsense reasoning.\" arXiv preprint arXiv:1806.02847 (2018).\n",
                "\n",
                "2. Brown, Tom, et al. \"Language models are few-shot learners.\" Advances in neural information processing systems 33 (2020): 1877-1901."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "To create the partial prompts and their completions, I'll just take some of [the code from here](https://github.com/EleutherAI/lm-evaluation-harness/blob/master/lm_eval/tasks/wsc273.py)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "_upper_pronouns = [\n",
                "    \"A\",\n",
                "    \"An\",\n",
                "    \"The\",\n",
                "    \"She\",\n",
                "    \"He\",\n",
                "    \"It\",\n",
                "    \"They\",\n",
                "    \"My\",\n",
                "    \"His\",\n",
                "    \"Her\",\n",
                "    \"Their\",\n",
                "]\n",
                "\n",
                "\n",
                "def _normalize_option(doc, option):\n",
                "    # Append `'s` to possessive determiner based options.\n",
                "    if doc[\"pronoun\"].lower() in [\"my\", \"his\", \"her\", \"our\", \"their\"]:\n",
                "        option += \"'s\"\n",
                "    # Appropriately lowercase the pronoun in the option.\n",
                "    pronoun = option.split()[0]\n",
                "    start_of_sentence = doc[\"text\"][doc[\"pronoun_loc\"] - 2] == \".\"\n",
                "    if not start_of_sentence and pronoun in _upper_pronouns:\n",
                "        return option.replace(pronoun, pronoun.lower())\n",
                "    return option\n",
                "\n",
                "\n",
                "def _process_doc(doc):\n",
                "    # The HF implementation of `wsc273` is not `partial evaluation` friendly.\n",
                "    doc[\"text\"] = doc[\"text\"].replace(\"  \", \" \")\n",
                "    doc[\"options\"][0] = _normalize_option(doc, doc[\"options\"][0])\n",
                "    doc[\"options\"][1] = _normalize_option(doc, doc[\"options\"][1])\n",
                "    return doc\n",
                "\n",
                "\n",
                "def partial_context(doc, option):\n",
                "    # Substitute the pronoun in the original text with the specified\n",
                "    # option and ignore everything after.\n",
                "    return doc[\"text\"][: doc[\"pronoun_loc\"]] + option\n",
                "\n",
                "\n",
                "def partial_target(doc):\n",
                "    # The target is everything after the document specified pronoun.\n",
                "    start_index = doc[\"pronoun_loc\"] + len(doc[\"pronoun\"])\n",
                "    return \" \" + doc[\"text\"][start_index:].strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_exploded = (\n",
                "    pd.DataFrame([_process_doc(doc) for doc in df.to_dict(\"records\")])\n",
                "    .explode(column=\"options\")\n",
                "    .rename(columns={\"options\": \"option\"})\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_exploded[\"prompt\"] = [\n",
                "    partial_context(doc, option)\n",
                "    for doc, option in zip(df_exploded.to_dict(\"records\"), df_exploded[\"option\"])\n",
                "]\n",
                "df_exploded[\"completion\"] = [\n",
                "    partial_target(doc) for doc in df_exploded.to_dict(\"records\")\n",
                "]\n",
                "## just in case\n",
                "df_exploded[\"prompt\"] = df_exploded[\"prompt\"].str.strip()\n",
                "df_exploded[\"completion\"] = df_exploded[\"completion\"].str.strip()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's look at the first 4 examples (8 records in the exploded df)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style type=\"text/css\">\n",
                            "</style>\n",
                            "<table id=\"T_5b58a\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th class=\"blank level0\" >&nbsp;</th>\n",
                            "      <th id=\"T_5b58a_level0_col0\" class=\"col_heading level0 col0\" >prompt</th>\n",
                            "      <th id=\"T_5b58a_level0_col1\" class=\"col_heading level0 col1\" >completion</th>\n",
                            "      <th id=\"T_5b58a_level0_col2\" class=\"col_heading level0 col2\" >label</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
                            "      <td id=\"T_5b58a_row0_col0\" class=\"data row0 col0\" >The city councilmen refused the demonstrators a permit because the city councilmen</td>\n",
                            "      <td id=\"T_5b58a_row0_col1\" class=\"data row0 col1\" >feared violence.</td>\n",
                            "      <td id=\"T_5b58a_row0_col2\" class=\"data row0 col2\" >0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
                            "      <td id=\"T_5b58a_row1_col0\" class=\"data row1 col0\" >The city councilmen refused the demonstrators a permit because the demonstrators</td>\n",
                            "      <td id=\"T_5b58a_row1_col1\" class=\"data row1 col1\" >feared violence.</td>\n",
                            "      <td id=\"T_5b58a_row1_col2\" class=\"data row1 col2\" >0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
                            "      <td id=\"T_5b58a_row2_col0\" class=\"data row2 col0\" >The city councilmen refused the demonstrators a permit because the city councilmen</td>\n",
                            "      <td id=\"T_5b58a_row2_col1\" class=\"data row2 col1\" >advocated violence.</td>\n",
                            "      <td id=\"T_5b58a_row2_col2\" class=\"data row2 col2\" >1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row3\" class=\"row_heading level0 row3\" >1</th>\n",
                            "      <td id=\"T_5b58a_row3_col0\" class=\"data row3 col0\" >The city councilmen refused the demonstrators a permit because the demonstrators</td>\n",
                            "      <td id=\"T_5b58a_row3_col1\" class=\"data row3 col1\" >advocated violence.</td>\n",
                            "      <td id=\"T_5b58a_row3_col2\" class=\"data row3 col2\" >1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row4\" class=\"row_heading level0 row4\" >2</th>\n",
                            "      <td id=\"T_5b58a_row4_col0\" class=\"data row4 col0\" >The trophy doesn't fit into the brown suitcase because the trophy</td>\n",
                            "      <td id=\"T_5b58a_row4_col1\" class=\"data row4 col1\" >is too large.</td>\n",
                            "      <td id=\"T_5b58a_row4_col2\" class=\"data row4 col2\" >0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row5\" class=\"row_heading level0 row5\" >2</th>\n",
                            "      <td id=\"T_5b58a_row5_col0\" class=\"data row5 col0\" >The trophy doesn't fit into the brown suitcase because the suitcase</td>\n",
                            "      <td id=\"T_5b58a_row5_col1\" class=\"data row5 col1\" >is too large.</td>\n",
                            "      <td id=\"T_5b58a_row5_col2\" class=\"data row5 col2\" >0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row6\" class=\"row_heading level0 row6\" >3</th>\n",
                            "      <td id=\"T_5b58a_row6_col0\" class=\"data row6 col0\" >The trophy doesn't fit into the brown suitcase because the trophy</td>\n",
                            "      <td id=\"T_5b58a_row6_col1\" class=\"data row6 col1\" >is too small.</td>\n",
                            "      <td id=\"T_5b58a_row6_col2\" class=\"data row6 col2\" >1</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_5b58a_level0_row7\" class=\"row_heading level0 row7\" >3</th>\n",
                            "      <td id=\"T_5b58a_row7_col0\" class=\"data row7 col0\" >The trophy doesn't fit into the brown suitcase because the suitcase</td>\n",
                            "      <td id=\"T_5b58a_row7_col1\" class=\"data row7 col1\" >is too small.</td>\n",
                            "      <td id=\"T_5b58a_row7_col2\" class=\"data row7 col2\" >1</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<pandas.io.formats.style.Styler at 0x12334d550>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display_df(df_exploded, columns=[\"prompt\", \"completion\", \"label\"], num_rows=8)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "I was dubious about how well the code worked, so I scanned more examples. There's a potential problem with the 54th example:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style type=\"text/css\">\n",
                            "</style>\n",
                            "<table id=\"T_be255\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th class=\"blank level0\" >&nbsp;</th>\n",
                            "      <th id=\"T_be255_level0_col0\" class=\"col_heading level0 col0\" >option</th>\n",
                            "      <th id=\"T_be255_level0_col1\" class=\"col_heading level0 col1\" >prompt</th>\n",
                            "      <th id=\"T_be255_level0_col2\" class=\"col_heading level0 col2\" >completion</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th id=\"T_be255_level0_row0\" class=\"row_heading level0 row0\" >54</th>\n",
                            "      <td id=\"T_be255_row0_col0\" class=\"data row0 col0\" >the gap</td>\n",
                            "      <td id=\"T_be255_row0_col1\" class=\"data row0 col1\" >There is a gap in the wall. You can see the garden through the gap</td>\n",
                            "      <td id=\"T_be255_row0_col2\" class=\"data row0 col2\" >.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_be255_level0_row1\" class=\"row_heading level0 row1\" >54</th>\n",
                            "      <td id=\"T_be255_row1_col0\" class=\"data row1 col0\" >the wall</td>\n",
                            "      <td id=\"T_be255_row1_col1\" class=\"data row1 col1\" >There is a gap in the wall. You can see the garden through the wall</td>\n",
                            "      <td id=\"T_be255_row1_col2\" class=\"data row1 col2\" >.</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<pandas.io.formats.style.Styler at 0x1204bd710>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display_df(df_exploded.loc[54], columns=[\"option\", \"prompt\", \"completion\"])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's see how many examples have this problem."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "18.0"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "_mask_corrupt = df_exploded[\"completion\"] == \".\"\n",
                "sum(_mask_corrupt) / 2  ## in the expoded df, there are 2 records per example"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Seems like a systematic issue we need to correct. The problem is that computing Pr('.' | prompt) for these wouldn't discriminate at all. The `option` does discriminate. So let's just take the `option` out of the `prompt` and move it to the `completion`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "_mask_corrupt = df_exploded[\"completion\"] == \".\"\n",
                "_wsc_corrupt = df_exploded.copy()[_mask_corrupt]\n",
                "assert all(\n",
                "    prompt.endswith(option)\n",
                "    for prompt, option in zip(_wsc_corrupt[\"prompt\"], _wsc_corrupt[\"option\"])\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "_prompts_fixed = [\n",
                "    remove_suffix(prompt, option)\n",
                "    for prompt, option in zip(_wsc_corrupt[\"prompt\"], _wsc_corrupt[\"option\"])\n",
                "]\n",
                "\n",
                "_completions_fixed = df_exploded.loc[_mask_corrupt, \"option\"]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_exploded.loc[_mask_corrupt, \"prompt\"] = _prompts_fixed\n",
                "df_exploded.loc[_mask_corrupt, \"completion\"] = _completions_fixed\n",
                "\n",
                "## just in case\n",
                "df_exploded[\"prompt\"] = df_exploded[\"prompt\"].str.strip()\n",
                "df_exploded[\"completion\"] = df_exploded[\"completion\"].str.strip()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<style type=\"text/css\">\n",
                            "</style>\n",
                            "<table id=\"T_91de3\">\n",
                            "  <thead>\n",
                            "    <tr>\n",
                            "      <th class=\"blank level0\" >&nbsp;</th>\n",
                            "      <th id=\"T_91de3_level0_col0\" class=\"col_heading level0 col0\" >option</th>\n",
                            "      <th id=\"T_91de3_level0_col1\" class=\"col_heading level0 col1\" >prompt</th>\n",
                            "      <th id=\"T_91de3_level0_col2\" class=\"col_heading level0 col2\" >completion</th>\n",
                            "      <th id=\"T_91de3_level0_col3\" class=\"col_heading level0 col3\" >label</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th id=\"T_91de3_level0_row0\" class=\"row_heading level0 row0\" >54</th>\n",
                            "      <td id=\"T_91de3_row0_col0\" class=\"data row0 col0\" >the gap</td>\n",
                            "      <td id=\"T_91de3_row0_col1\" class=\"data row0 col1\" >There is a gap in the wall. You can see the garden through</td>\n",
                            "      <td id=\"T_91de3_row0_col2\" class=\"data row0 col2\" >the gap</td>\n",
                            "      <td id=\"T_91de3_row0_col3\" class=\"data row0 col3\" >0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th id=\"T_91de3_level0_row1\" class=\"row_heading level0 row1\" >54</th>\n",
                            "      <td id=\"T_91de3_row1_col0\" class=\"data row1 col0\" >the wall</td>\n",
                            "      <td id=\"T_91de3_row1_col1\" class=\"data row1 col1\" >There is a gap in the wall. You can see the garden through</td>\n",
                            "      <td id=\"T_91de3_row1_col2\" class=\"data row1 col2\" >the wall</td>\n",
                            "      <td id=\"T_91de3_row1_col3\" class=\"data row1 col3\" >0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n"
                        ],
                        "text/plain": [
                            "<pandas.io.formats.style.Styler at 0x1228bbd10>"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "display_df(df_exploded.loc[54], columns=[\"option\", \"prompt\", \"completion\", \"label\"])"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "There, all better."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Run model"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For WSC, the probability distribution over classes is uniform. So we'll use `prior=None`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "metadata": {},
            "outputs": [],
            "source": [
                "examples = [\n",
                "    Example(\n",
                "        prompt=record[\"prompt\"],\n",
                "        completions=(record[\"completion\"],),\n",
                "        prior=None,\n",
                "        normalize=False,\n",
                "    )\n",
                "    for record in df_exploded.to_dict(\"records\")\n",
                "]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "546"
                        ]
                    },
                    "execution_count": 17,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "len(examples)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e2ae64104b054ab9a541b45660da3f7c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "log-probs:   0%|          | 0/546 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# $0.02\n",
                "pred_probs = openai.classify.predict_proba_examples(\n",
                "    examples, model=\"gpt-3.5-turbo-instruct\", ask_if_ok=True\n",
                ")"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Score"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We flattened/exploded the examples so that there's one record for each (example, option) pair. To go back to the original format, we just need to batch `pred_probs`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "def process_probs(probs: np.ndarray, batch_sizes) -> np.ndarray:\n",
                "    if len(probs.shape) > 1:\n",
                "        raise ValueError(\"Expected probs to have shape (n,).\")\n",
                "    pred_probs_unnorm = list(_batch.variable(probs, batch_sizes))\n",
                "    pred_probs_unnorm: np.ndarray = np.array(pred_probs_unnorm)\n",
                "    return pred_probs_unnorm / pred_probs_unnorm.sum(axis=1, keepdims=True)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "For WSC, the scoring metric is accuracy."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8937728937728938"
                        ]
                    },
                    "execution_count": 20,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "batch_sizes = df[\"options\"].apply(len)  # ik they're all 2\n",
                "pred_probs_norm = process_probs(pred_probs[:, 0], batch_sizes)\n",
                "(pred_probs_norm.argmax(axis=1) == df[\"label\"]).mean()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "This roughly matches the performance in the GPT-3 paper (section 3.4). I guess there wasn't much to learn from this b/c we're both basically using the same method. Nice to see that the code kinda works I guess."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "While we're were, let's see how `text-curie-001` performs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4d0e6f50d9b64067b43bfea17c75c05d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "log-probs:   0%|          | 0/546 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "# $0.02\n",
                "pred_probs_curie = openai.classify.predict_proba_examples(\n",
                "    examples, model=\"text-curie-001\", ask_if_ok=True\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0.8424908424908425"
                        ]
                    },
                    "execution_count": 22,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "pred_probs_norm_curie = process_probs(pred_probs_curie[:, 0], batch_sizes)\n",
                "(pred_probs_norm_curie.argmax(axis=1) == df[\"label\"]).mean()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Not too shabby. But again, WSC is contaminated."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "lmc",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.5"
        },
        "orig_nbformat": 4,
        "vscode": {
            "interpreter": {
                "hash": "68daa88f78f5c448099edb3a6d3dee27486a6add8824ae1cbe4c903ef8faec70"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
