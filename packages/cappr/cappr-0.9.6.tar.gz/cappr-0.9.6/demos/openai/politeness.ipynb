{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install \"cappr[openai]\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "copied over from https://github.com/kddubey/cappr/blob/main/demos/utils.py so that this\n",
    "notebook can be run anywhere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Optional, Union\n",
    "\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def display_df(\n",
    "    df: pd.DataFrame,\n",
    "    columns: Optional[list[str]] = None,\n",
    "    num_rows: Union[int, None] = 3,\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays `df.head(num_rows)[columns]` without truncating columns. If\n",
    "    possible, render any newlines.\n",
    "    \"\"\"\n",
    "    if columns is None:\n",
    "        columns = df.columns\n",
    "    if num_rows is None:\n",
    "        num_rows = len(df)\n",
    "    df_head_styled = df.head(num_rows)[columns].style\n",
    "    with pd.option_context(\"max_colwidth\", -1):\n",
    "        ## I'm not sure why try-except doesn't work w/ display(), so instead\n",
    "        ## check the necessary uniqueness condition before running it\n",
    "        if df.index.is_unique:\n",
    "            display(\n",
    "                df_head_styled.set_properties(\n",
    "                    **{\"text-align\": \"left\", \"white-space\": \"pre-wrap\"}\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            ## `Styler.apply` and `.applymap` are not compatible with non-unique\n",
    "            ## index or columns\n",
    "            display(df_head_styled)\n",
    "\n",
    "\n",
    "def remove_prefix(string: str, prefix: str) -> str:\n",
    "    if string.startswith(prefix):\n",
    "        return string[len(prefix) :]\n",
    "    return string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-shot prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from cappr import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_701ac_row0_col0, #T_701ac_row0_col1, #T_701ac_row1_col0, #T_701ac_row1_col1, #T_701ac_row2_col0, #T_701ac_row2_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_701ac\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_701ac_level0_col0\" class=\"col_heading level0 col0\" >text</th>\n",
       "      <th id=\"T_701ac_level0_col1\" class=\"col_heading level0 col1\" >class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_701ac_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_701ac_row0_col0\" class=\"data row0 col0\" >Excuse me? What are you accusing me of doing?</td>\n",
       "      <td id=\"T_701ac_row0_col1\" class=\"data row0 col1\" >impolite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_701ac_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_701ac_row1_col0\" class=\"data row1 col0\" >I don't understand Tasc0??</td>\n",
       "      <td id=\"T_701ac_row1_col1\" class=\"data row1 col1\" >impolite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_701ac_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_701ac_row2_col0\" class=\"data row2 col0\" >Well, you leaved me also curious. Why was it not appropriate?</td>\n",
       "      <td id=\"T_701ac_row2_col1\" class=\"data row2 col1\" >impolite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1897eedb610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"https://s.cleanlab.ai/stanford-politeness/fine-tuning/test.csv\")\n",
    "df = df.rename(columns={'prompt': 'text', 'completion': 'class'})\n",
    "display_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['impolite', 'neutral', 'polite']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = df['class'].sort_values().unique().tolist()\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use the training data to manually select one example per class. In this case I\n",
    "figured that the examples below seem good enough. Maybe there should be a package which\n",
    "auto-selects the examples via cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_train = pd.read_csv(\"https://s.cleanlab.ai/stanford-politeness/fine-tuning/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_36b75_row0_col0, #T_36b75_row0_col1, #T_36b75_row1_col0, #T_36b75_row1_col1, #T_36b75_row2_col0, #T_36b75_row2_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_36b75\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_36b75_level0_col0\" class=\"col_heading level0 col0\" >prompt</th>\n",
       "      <th id=\"T_36b75_level0_col1\" class=\"col_heading level0 col1\" >completion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_36b75_level0_row0\" class=\"row_heading level0 row0\" >1144</th>\n",
       "      <td id=\"T_36b75_row0_col0\" class=\"data row0 col0\" >I didn't see your internal link, I put it back.  <url> isn't orphaned, what are you talking about?</td>\n",
       "      <td id=\"T_36b75_row0_col1\" class=\"data row0 col1\" >impolite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36b75_level0_row1\" class=\"row_heading level0 row1\" >1625</th>\n",
       "      <td id=\"T_36b75_row1_col0\" class=\"data row1 col0\" >One to go. Shouldn't \"now welcome\" be \"not welcome\"?</td>\n",
       "      <td id=\"T_36b75_row1_col1\" class=\"data row1 col1\" >neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_36b75_level0_row2\" class=\"row_heading level0 row2\" >204</th>\n",
       "      <td id=\"T_36b75_row2_col0\" class=\"data row2 col0\" >Greetings, and thank you for your cogent remarks at <url>.  Would you be interested in voting in the straw poll <url> as well?</td>\n",
       "      <td id=\"T_36b75_row2_col1\" class=\"data row2 col1\" >polite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x189107b4310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "examples_df = (_train\n",
    "               .groupby('completion')\n",
    "               .sample(1, random_state=42))\n",
    "display_df(examples_df, num_rows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I didn't see your internal link, I put it back.  <url> isn't orphaned, what are you talking about?\n",
      "Tone: impolite\n",
      "\n",
      "Text: One to go. Shouldn't \"now welcome\" be \"not welcome\"?\n",
      "Tone: neutral\n",
      "\n",
      "Text: Greetings, and thank you for your cogent remarks at <url>.  Would you be interested in voting in the straw poll <url> as well?\n",
      "Tone: polite\n"
     ]
    }
   ],
   "source": [
    "examples_str = '\\n\\n'.join([f\"Text: {record['prompt']}\\nTone: {record['completion']}\"\n",
    "                            for record in examples_df.to_dict('records')])\n",
    "print(examples_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_mc(text: str):\n",
    "    return ( 'Here are examples of texts and their tones.\\n\\n'\n",
    "            f'{examples_str}\\n\\n'\n",
    "            f'The tone of this piece of text:\\n'\n",
    "            f'\"{text}\"\\n'\n",
    "             'is\\n'\n",
    "             'A. impolite\\n'\n",
    "             'B. neutral\\n'\n",
    "             'C. polite\\n\\n'\n",
    "             'Answer A or B or C.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_72cf7_row0_col0, #T_72cf7_row0_col1 {\n",
       "  text-align: left;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_72cf7\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_72cf7_level0_col0\" class=\"col_heading level0 col0\" >prompt_mc</th>\n",
       "      <th id=\"T_72cf7_level0_col1\" class=\"col_heading level0 col1\" >class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_72cf7_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_72cf7_row0_col0\" class=\"data row0 col0\" >Here are examples of texts and their tones.\n",
       "\n",
       "Text: I didn't see your internal link, I put it back.  <url> isn't orphaned, what are you talking about?\n",
       "Tone: impolite\n",
       "\n",
       "Text: One to go. Shouldn't \"now welcome\" be \"not welcome\"?\n",
       "Tone: neutral\n",
       "\n",
       "Text: Greetings, and thank you for your cogent remarks at <url>.  Would you be interested in voting in the straw poll <url> as well?\n",
       "Tone: polite\n",
       "\n",
       "The tone of this piece of text:\n",
       "\"Excuse me? What are you accusing me of doing?\"\n",
       "is\n",
       "A. impolite\n",
       "B. neutral\n",
       "C. polite\n",
       "\n",
       "Answer A or B or C.</td>\n",
       "      <td id=\"T_72cf7_row0_col1\" class=\"data row0 col1\" >impolite</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x189107b4fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['prompt_mc'] = [prompt_mc(text) for text in df['text']]\n",
    "display_df(df, columns=['prompt_mc', 'class'], num_rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba55c7cf7fb493e935f7d877a036be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Completing chats:   0%|          | 0/480 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## $0.17\n",
    "choices_chat = (openai.api\n",
    "                .gpt_chat_complete(df['prompt_mc'],\n",
    "                                   ask_if_ok=True,\n",
    "                                   max_tokens=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_completion(completion: str, class_chars,\n",
    "                       prefix_remove: str='Answer ', strip_chars: str=' \\n.',\n",
    "                       default=-1) -> int:\n",
    "    if any(len(class_char) != 1 for class_char in class_chars):\n",
    "        raise ValueError('Elements of class_chars must be a single character.')\n",
    "    completion = remove_prefix(completion, prefix_remove)\n",
    "    completion_stripped = completion.strip(strip_chars)\n",
    "    if not completion_stripped:\n",
    "        return default\n",
    "    completion_char_lower = completion_stripped[0].lower()\n",
    "    class_chars_lower = [class_char.lower() for class_char in class_chars]\n",
    "    try:\n",
    "        return class_chars_lower.index(completion_char_lower)\n",
    "    except ValueError:\n",
    "        return default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "completions_chat = pd.Series([choice['message']['content']\n",
    "                              for choice in choices_chat],\n",
    "                             index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classes_chat = pd.Series([classes[process_completion(completion, ('A', 'B', 'C'),\n",
    "                                                          default=1)]\n",
    "                               for completion in completions_chat],\n",
    "                              index=df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7020833333333333"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pred_classes_chat == df['class']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035416666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## rough dollar cost per classification\n",
    "0.17/len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prompt(text: str) -> str:\n",
    "#     return (f'{examples_str}\\n\\n'\n",
    "#             f'Text: {text}\\n'\n",
    "#              'Tone:')\n",
    "\n",
    "# df['prompt'] = [prompt(text) for text in df['text']]\n",
    "# display_df(df, columns=['prompt', 'class'], num_rows=1)\n",
    "\n",
    "# ## $4.2\n",
    "# preds = (openai.classify\n",
    "#          .predict(prompts=df['prompt'].tolist(),\n",
    "#                   completions=classes,\n",
    "#                   model='text-davinci-003',\n",
    "#                   ask_if_ok=True))\n",
    "# (pd.Series(preds, index=df.index) == df['class']).mean()\n",
    "# ## 0.70625"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cappr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
