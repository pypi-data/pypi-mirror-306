{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onOeCT_HbGMC"
      },
      "source": [
        "In its current form, you must run this notebook on a GPU. A T4 is sufficient. It's free\n",
        "on [Google\n",
        "Colab](https://stackoverflow.com/questions/62596466/how-can-i-run-notebooks-of-a-github-project-in-google-colab/67344477#67344477).\n",
        "You can technically run this notebook on a CPU (with minor adjustments), but then it'll\n",
        "take hours. We'll be running the model 1000 times!\n",
        "\n",
        "**Description**: for a [4 GB 4-bit Llama 2 chat\n",
        "model](https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/blob/main/llama-2-7b-chat.Q4_0.gguf)\n",
        "and the [COPA](https://people.ict.usc.edu/~gordon/copa.html) classification task, this\n",
        "notebook demonstrates that\n",
        "\n",
        "1. multiple choice text generation is not effective; it recovers 69% of the accuracy of\n",
        "   OpenAI's `gpt-3.5-turbo`\n",
        "2. CAPPr is effective; for this dataset, CAPPr recovers 91% of the accuracy of OpenAI's\n",
        "   `gpt-3.5-turbo`, and will never require post-processing of the output.\n",
        "\n",
        "**Contamination notice**: I don't know whether Llama 2 was trained on any COPA data. If\n",
        "it was, but there's no interaction between the method (CAPPr vs text generation) and\n",
        "training, then the difference between performances can be studied.\n",
        "\n",
        "**Estimated run time**: ~10 min."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H2cqyOvbGMT"
      },
      "source": [
        "[Install packages](#install-packages)\n",
        "\n",
        "[Download model](#download-model)\n",
        "\n",
        "[Utils](#utils)\n",
        "\n",
        "[Load data](#load-data)\n",
        "\n",
        "[The problem](#the-problem)\n",
        "\n",
        "[Write prompt](#write-prompt)\n",
        "\n",
        "[The solution](#the-solution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3edTvevkoCCR"
      },
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_-mtmZuccEf"
      },
      "source": [
        "For CPU, just do\n",
        "\n",
        "```\n",
        "!pip install llama-cpp-python\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Heya6HkdJyE"
      },
      "source": [
        "For GPU (ty [this comment](https://github.com/ggerganov/llama.cpp/issues/128#issuecomment-1604696753)):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KuyxVtifKFeS"
      },
      "outputs": [],
      "source": [
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 pip install llama-cpp-python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H2ukkr1cy6Z"
      },
      "source": [
        "I'm gonna install `cappr` from source b/c sometimes I use this notebook to statistically\n",
        "gut check code changes.\n",
        "\n",
        "I'll also install the `demos` extras for NLP datasets.\n",
        "\n",
        "In your local env, you'd just do:\n",
        "\n",
        "```\n",
        "pip install \"cappr[llama-cpp]\"\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NicJ2-6Hcump"
      },
      "outputs": [],
      "source": [
        "!pip install \"cappr[demos] @ git+https://github.com/kddubey/cappr.git\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A22iSuqGVtr7"
      },
      "source": [
        "# Download model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTx6xWlXfVWN"
      },
      "source": [
        "The model is a [4 GB 4-bit Llama 2 chat\n",
        "model](https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/blob/main/llama-2-7b-chat.Q4_0.gguf) with 7B parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkMaqHovEo_1",
        "outputId": "b6e81b5c-71ed-453b-a7e3-b4570318f17f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "downloading https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_0.gguf to /root/.cache/huggingface/hub/tmp8tg0r5a3\n",
            "Downloading (â€¦)-2-7b-chat.Q4_0.gguf: 100% 3.83G/3.83G [01:36<00:00, 39.8MB/s]\n",
            "Storing https://huggingface.co/TheBloke/Llama-2-7b-Chat-GGUF/resolve/main/llama-2-7b-chat.Q4_0.gguf in local_dir at ./llama-2-7b-chat.Q4_0.gguf (not cached).\n",
            "./llama-2-7b-chat.Q4_0.gguf\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli download \\\n",
        "TheBloke/Llama-2-7b-Chat-GGUF \\\n",
        "llama-2-7b-chat.Q4_0.gguf \\\n",
        "--local-dir . \\\n",
        "--local-dir-use-symlinks False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UC6fONZlV1XF"
      },
      "outputs": [],
      "source": [
        "model_path = \"./llama-2-7b-chat.Q4_0.gguf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WNW0Cz1sbGMX"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from pprint import pprint\n",
        "from typing import Collection, Literal, Sequence\n",
        "\n",
        "import datasets\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from llama_cpp import Llama\n",
        "\n",
        "from cappr import Example\n",
        "from cappr.llama_cpp import classify"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xegEtmskckgp",
        "outputId": "e823e02c-9759-480e-d5d4-6674938cf9e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import torch\n",
        "n_gpu_layers = -1 if torch.cuda.is_available() else 0\n",
        "n_gpu_layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-JyALQPE-c1",
        "outputId": "ac270a54-4349-48c9-e3ee-fdbca01bc468"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ],
      "source": [
        "model = Llama(model_path=model_path, n_gpu_layers=n_gpu_layers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcMpkOdlcapS"
      },
      "source": [
        "# Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljguOue9cfcm"
      },
      "source": [
        "Copied from [here](https://github.com/kddubey/cappr/blob/main/demos/utils.py) so that this notebook can be run anywhere."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "vIdleXW_ccBH"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "from typing import Optional, Union\n",
        "\n",
        "from IPython.display import display\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def display_df(\n",
        "    df: pd.DataFrame,\n",
        "    columns: Optional[list[str]] = None,\n",
        "    num_rows: Union[int, None] = 3,\n",
        "):\n",
        "    \"\"\"\n",
        "    Displays `df.head(num_rows)[columns]` without truncating columns. If\n",
        "    possible, render any newlines.\n",
        "    \"\"\"\n",
        "    if columns is None:\n",
        "        columns = df.columns\n",
        "    if num_rows is None:\n",
        "        num_rows = len(df)\n",
        "    df_head_styled = df.head(num_rows)[columns].style\n",
        "    with pd.option_context(\"max_colwidth\", -1):\n",
        "        # I'm not sure why try-except doesn't work w/ display(), so instead\n",
        "        # check the necessary uniqueness condition before running it\n",
        "        if df.index.is_unique:\n",
        "            display(\n",
        "                df_head_styled.set_properties(\n",
        "                    **{\"text-align\": \"left\", \"white-space\": \"pre-wrap\"}\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            # `Styler.apply` and `.applymap` are not compatible with non-unique\n",
        "            # index or columns\n",
        "            display(df_head_styled)\n",
        "\n",
        "\n",
        "def remove_suffix(string: str, suffix: str):\n",
        "    if string.endswith(suffix):\n",
        "        return string[: -len(suffix)]\n",
        "    return string\n",
        "\n",
        "\n",
        "def remove_prefix(string: str, prefix: str) -> str:\n",
        "    if string.startswith(prefix):\n",
        "        return string[len(prefix) :]\n",
        "    return string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcCXl84vbGMd"
      },
      "source": [
        "# Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8cYXqVubGMe"
      },
      "source": [
        "For this MVP, let's evaluate on the [Choice of Plausible Alternatives (COPA) task](https://people.ict.usc.edu/~gordon/copa.html). I picked this first b/c I read it has multi-token labels, in some sense.\n",
        "\n",
        "The classification problem is to pick 1 of 2 alternatives which caused or resulted in the premise. Here are two example pulled from the website:\n",
        "\n",
        "Example 1\n",
        "\n",
        "> Premise: The man broke his toe. What was the CAUSE of this?\n",
        ">\n",
        "> Alternative 1: He got a hole in his sock.\n",
        ">\n",
        "> Alternative 2: He dropped a hammer on his foot.\n",
        "\n",
        "\n",
        "Example 2\n",
        "\n",
        "> Premise: I tipped the bottle. What happened as a RESULT?\n",
        ">\n",
        "> Alternative 1: The liquid in the bottle froze.\n",
        ">\n",
        "> Alternative 2: The liquid in the bottle poured out.\n",
        "\n",
        "A classifier should predict Alternative 2 for Example 1, and Alternative 2 for Example 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfcnx1mbbGMi"
      },
      "source": [
        "The test set labels are hidden, so I'll score this zero-shot classifier on the train and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0WayD0g5bGMj"
      },
      "outputs": [],
      "source": [
        "def load_super_glue(task_id: str, split: str):\n",
        "    return pd.DataFrame(datasets\n",
        "                        .load_dataset('super_glue', task_id, split=split))\n",
        "\n",
        "\n",
        "df = (pd.concat((load_super_glue('copa', 'train'),\n",
        "                 load_super_glue('copa', 'validation')))\n",
        "      .reset_index(drop=True)) # idx column is only unique w/in splits! fuhgetaboutit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlOIxn66bGMm",
        "outputId": "3c7e0c3b-be8f-4ced-d874-aad98374968d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8UYnBCHtbGNH",
        "outputId": "08323fa6-856b-4f26-9c4c-5a54edfa6f07"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4c40c5d9-4642-4b45-9b74-974ada88856d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>premise</th>\n",
              "      <th>choice1</th>\n",
              "      <th>choice2</th>\n",
              "      <th>question</th>\n",
              "      <th>idx</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My body cast a shadow over the grass.</td>\n",
              "      <td>The sun was rising.</td>\n",
              "      <td>The grass was cut.</td>\n",
              "      <td>cause</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The woman tolerated her friend's difficult beh...</td>\n",
              "      <td>The woman knew her friend was going through a ...</td>\n",
              "      <td>The woman felt that her friend took advantage ...</td>\n",
              "      <td>cause</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The women met for coffee.</td>\n",
              "      <td>The cafe reopened in a new location.</td>\n",
              "      <td>They wanted to catch up with each other.</td>\n",
              "      <td>cause</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The runner wore shorts.</td>\n",
              "      <td>The forecast predicted high temperatures.</td>\n",
              "      <td>She planned to run along the beach.</td>\n",
              "      <td>cause</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The guests of the party hid behind the couch.</td>\n",
              "      <td>It was a surprise party.</td>\n",
              "      <td>It was a birthday party.</td>\n",
              "      <td>cause</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c40c5d9-4642-4b45-9b74-974ada88856d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4c40c5d9-4642-4b45-9b74-974ada88856d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4c40c5d9-4642-4b45-9b74-974ada88856d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78700820-12ec-4737-a88f-592716362beb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78700820-12ec-4737-a88f-592716362beb')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78700820-12ec-4737-a88f-592716362beb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                             premise  \\\n",
              "0              My body cast a shadow over the grass.   \n",
              "1  The woman tolerated her friend's difficult beh...   \n",
              "2                          The women met for coffee.   \n",
              "3                            The runner wore shorts.   \n",
              "4      The guests of the party hid behind the couch.   \n",
              "\n",
              "                                             choice1  \\\n",
              "0                                The sun was rising.   \n",
              "1  The woman knew her friend was going through a ...   \n",
              "2               The cafe reopened in a new location.   \n",
              "3          The forecast predicted high temperatures.   \n",
              "4                           It was a surprise party.   \n",
              "\n",
              "                                             choice2 question  idx  label  \n",
              "0                                 The grass was cut.    cause    0      0  \n",
              "1  The woman felt that her friend took advantage ...    cause    1      0  \n",
              "2           They wanted to catch up with each other.    cause    2      1  \n",
              "3                She planned to run along the beach.    cause    3      0  \n",
              "4                           It was a birthday party.    cause    4      0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgNUWO0ZbGNv"
      },
      "source": [
        "# The problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l58CPJ32qucO"
      },
      "source": [
        "The most straightforward way to solve this task is to point to each alternative with a\n",
        "single letter, and hope that the LM samples/generates the correct letter. The prompt is\n",
        "effectively a multiple choice question."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QowIM4eJbGN0"
      },
      "source": [
        "For example:\n",
        "\n",
        "```\n",
        "The man broke his toe because\n",
        "A. He got a hole in his sock.\n",
        "B. He dropped a hammer on his foot.\n",
        "Answer A or B.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PDtZShBKteyZ"
      },
      "outputs": [],
      "source": [
        "def _conjunction(question: Literal[\"cause\", \"effect\"]):\n",
        "    if question == \"cause\":\n",
        "        return \" because\"\n",
        "    elif question == \"effect\":\n",
        "        return \", so\"\n",
        "    else:\n",
        "        raise ValueError(\"question must be 'cause' or 'effect'. Got \" f\"{question}.\")\n",
        "\n",
        "\n",
        "def prompt(premise: str, question: Literal[\"cause\", \"effect\"]):\n",
        "    conjunction = _conjunction(question)\n",
        "    return f'{premise.strip(\". \")}{conjunction}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "7RUrWpZNbGN1",
        "outputId": "439a8851-91cc-411d-f51d-86a36f9045d7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_52b0b_row0_col0, #T_52b0b_row0_col1, #T_52b0b_row1_col0, #T_52b0b_row1_col1, #T_52b0b_row2_col0, #T_52b0b_row2_col1 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_52b0b\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_52b0b_level0_col0\" class=\"col_heading level0 col0\" >prompt_mc</th>\n",
              "      <th id=\"T_52b0b_level0_col1\" class=\"col_heading level0 col1\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_52b0b_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_52b0b_row0_col0\" class=\"data row0 col0\" >My body cast a shadow over the grass because\n",
              "A. The sun was rising.\n",
              "B. The grass was cut.\n",
              "Answer A or B.</td>\n",
              "      <td id=\"T_52b0b_row0_col1\" class=\"data row0 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_52b0b_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_52b0b_row1_col0\" class=\"data row1 col0\" >The woman tolerated her friend's difficult behavior because\n",
              "A. The woman knew her friend was going through a hard time.\n",
              "B. The woman felt that her friend took advantage of her kindness.\n",
              "Answer A or B.</td>\n",
              "      <td id=\"T_52b0b_row1_col1\" class=\"data row1 col1\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_52b0b_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_52b0b_row2_col0\" class=\"data row2 col0\" >The women met for coffee because\n",
              "A. The cafe reopened in a new location.\n",
              "B. They wanted to catch up with each other.\n",
              "Answer A or B.</td>\n",
              "      <td id=\"T_52b0b_row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79ca75c156c0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "def prompt_mc(\n",
        "    premise: str, question: Literal[\"cause\", \"effect\"], choice1: str, choice2: str\n",
        "):\n",
        "    return (\n",
        "        f\"{prompt(premise, question)}\\n\"\n",
        "        f\"A. {choice1}\\n\"\n",
        "        f\"B. {choice2}\\n\"\n",
        "        \"Answer A or B.\"\n",
        "    )\n",
        "\n",
        "\n",
        "df[\"prompt_mc\"] = [\n",
        "    prompt_mc(\n",
        "        record[\"premise\"], record[\"question\"], record[\"choice1\"], record[\"choice2\"]\n",
        "    )\n",
        "    for record in df.to_dict(\"records\")\n",
        "]\n",
        "\n",
        "\n",
        "display_df(df, columns=[\"prompt_mc\", \"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFuoUoBkbGOO"
      },
      "source": [
        "(It turns out that GitHub doesn't render the newlines, but I promise they're there!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k29lTlDt1ZrG"
      },
      "source": [
        "The [notebook\n",
        "here](https://github.com/kddubey/cappr/blob/main/demos/openai/superglue/copa.ipynb)\n",
        "demonstrates that this prompt is effective for bigger OpenAI models:\n",
        "`gpt-3.5-turbo-instruct` and `gpt-3.5-turbo`. Let's see how it performs for Llama 2.\n",
        "\n",
        "Note after experiments: this prompt seems to be the best I can do w/ text generation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PXv6OARi1w3m"
      },
      "outputs": [],
      "source": [
        "# if we're using a chat model, let's make sure we're formatting the prompt correctly\n",
        "llama_chat_template = \"\"\"\n",
        "<s>[INST] <<SYS>>\n",
        "{system_prompt}\n",
        "<</SYS>>\n",
        "\n",
        "{user_message} [/INST]\n",
        "\"\"\".lstrip(\n",
        "    \"\\n\"\n",
        ")\n",
        "\n",
        "system_prompt_copa = (\n",
        "    \"Identify the cause or effect of a premise given two choices. Each choice \"\n",
        "    \"is identified by a letter, A or B.\\n\"\n",
        "    \"Respond only with the letter corresponding to the correct cause or effect.\"\n",
        ")\n",
        "\n",
        "df[\"prompt_mc_chat\"] = [\n",
        "    llama_chat_template.format(\n",
        "        system_prompt=system_prompt_copa, user_message=prompt_mc\n",
        "    )\n",
        "    for prompt_mc in df[\"prompt_mc\"]\n",
        "]\n",
        "\n",
        "if \"chat\" in model_path.lower():\n",
        "    prompt_mc_column = \"prompt_mc_chat\"\n",
        "else:\n",
        "    prompt_mc_column = \"prompt_mc\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aSsrC1x3XLa",
        "outputId": "891d81b6-3883-44aa-81c7-debb151fc9d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<s>[INST] <<SYS>>\n",
            "Identify the cause or effect of a premise given two choices. Each choice is identified by a letter, A or B.\n",
            "Respond only with the letter corresponding to the correct cause or effect.\n",
            "<</SYS>>\n",
            "\n",
            "My body cast a shadow over the grass because\n",
            "A. The sun was rising.\n",
            "B. The grass was cut.\n",
            "Answer A or B. [/INST]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(df[prompt_mc_column].iloc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OaEEYAbrVf7"
      },
      "source": [
        "Generate MC answers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2b487626a056424098ec431a53ace749",
            "80592af7ea3a454783de4d5ecc830777",
            "8b8def7e1bdb4201aacf26f2ccb396b5",
            "a34db07b4fb14bed8708da1a29329db3",
            "1aca872f20b14f01b1700613cab4566c",
            "cdeb2b3221d5497ba5d3130a796222b2",
            "c7cef39b81664a1fae26fe407c5f01e5",
            "6b45005dfa5f43479b6bf087229f9435",
            "5670c4d9ddee43b69448ba05bf21e964",
            "6f8b2c58245d4bdabdc9b1c35ff9529a",
            "ad74d042c44d45ebaf28cf5cade11f09"
          ]
        },
        "id": "V1J5uu1wjGsH",
        "outputId": "3e190b39-a9c3-469b-f8da-1ae671cb63a7"
      },
      "outputs": [],
      "source": [
        "completions = []\n",
        "for _prompt in tqdm(df[prompt_mc_column], total=len(df), desc=\"Sampling\"):\n",
        "    response = model(_prompt, max_tokens=5, temperature=0)\n",
        "    completion = response['choices'][0]['text']\n",
        "    completions.append(completion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMtKqqdPlggb",
        "outputId": "ae124863-f817-4fe1-beff-5cb17bf125fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "59                       B\n",
              "31            B. He grew a\n",
              "392                      B\n",
              "132    B. The woman apolog\n",
              "239                      A\n",
              "277                      B\n",
              "35                       A\n",
              "348                      B\n",
              "290                      B\n",
              "352                      B\n",
              "dtype: object"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(completions).sample(n=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izyq3REq7w84"
      },
      "source": [
        "When you're doing text generation, you often have to write this sort of data-dependent\n",
        "and model-dependent function:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NR4DkFgm4KhJ"
      },
      "outputs": [],
      "source": [
        "def process_completion(\n",
        "    completion: str,\n",
        "    class_chars: Sequence[str],\n",
        "    prefixes_remove: Collection[str] = (\"Answer \",),\n",
        "    strip_chars: str = \" \\n.\",\n",
        "    default=-1,\n",
        ") -> int:\n",
        "    if any(len(class_char) != 1 for class_char in class_chars):\n",
        "        raise ValueError(\"Elements of class_chars must be a single character.\")\n",
        "\n",
        "    completion_stripped = completion.strip(strip_chars)\n",
        "    if not completion_stripped:\n",
        "        return default\n",
        "    for prefix_remove in prefixes_remove:\n",
        "        completion_stripped_rm = remove_prefix(completion_stripped, prefix_remove)\n",
        "    if not completion:\n",
        "        return default\n",
        "    completion_char_lower = completion_stripped_rm[0].lower()\n",
        "    class_chars_lower = [class_char.lower() for class_char in class_chars]\n",
        "    try:\n",
        "        return class_chars_lower.index(completion_char_lower)\n",
        "    except ValueError:\n",
        "        return default"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "nIoergB64Mak"
      },
      "outputs": [],
      "source": [
        "class_chars = ('A', 'B')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9UnausK74XjN"
      },
      "outputs": [],
      "source": [
        "pred_classes_text_gen = [\n",
        "    process_completion(completion, class_chars)\n",
        "    for completion in completions\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA-Mxvf841lv"
      },
      "source": [
        "How many of the sampled completions could be mapped to a label 0 or 1?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sua4kuar4bAJ",
        "outputId": "ab0cfe88-580d-49d8-cf13-b8043c9d273a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.994"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(pd.Series(pred_classes_text_gen) != -1).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwBK97kYAuqi"
      },
      "source": [
        "That's nice. But how accurate are the predictions?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsMAayo04gWC",
        "outputId": "d5443fe9-dee1-4c79-9495-184e7b336ff9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.624"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(pred_classes_text_gen == df['label']).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzDVVD1bmMEi"
      },
      "source": [
        "If you don't use an instruction-trained model, only a fraction of the LM's responses\n",
        "contain a letter which is easy to parse. Computing acccuracy is kind of pointless; we\n",
        "don't even have real predictions.\n",
        "\n",
        "If you do use an instruction-trained model, you get real predictions, but they're\n",
        "incorrect too often.\n",
        "\n",
        "Unfortunately, for smaller or less-instruction-trained LMs, text generation can raise\n",
        "more problems than it solves. This result aligns with the one found in the [demo for\n",
        "`text-curie-001`](https://github.com/kddubey/cappr/blob/main/demos/superglue/copa.ipynb).\n",
        "Sampling structured outputs from smaller language models is not statistically\n",
        "performant.\n",
        "\n",
        "What do we do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwqNyZSqbGNJ"
      },
      "source": [
        "# Write prompt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECMyLwrVprBh"
      },
      "source": [
        "We should take advantage of the fact that models like Llama 2 were extensively trained for a simple task: predict the next token."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Io8zpoLibGNK"
      },
      "source": [
        "A simple way to model COPA is to prompt an LM with (for Example 1):\n",
        "\n",
        "```\n",
        "The man broke his toe because\n",
        "```\n",
        "\n",
        "and use the LM to estimate the probabilities of the 2 alternatives conditional on this prompt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "0xlrUCdJbGNT"
      },
      "outputs": [],
      "source": [
        "df[\"prompt\"] = [\n",
        "    prompt(premise, question)\n",
        "    for premise, question in zip(df[\"premise\"], df[\"question\"])\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "id": "6zH9PPBpbGNd",
        "outputId": "0222ede2-c401-4aae-cb1c-02c7aa5e8154"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_16cd2_row0_col0, #T_16cd2_row0_col1, #T_16cd2_row0_col2, #T_16cd2_row0_col3, #T_16cd2_row1_col0, #T_16cd2_row1_col1, #T_16cd2_row1_col2, #T_16cd2_row1_col3, #T_16cd2_row2_col0, #T_16cd2_row2_col1, #T_16cd2_row2_col2, #T_16cd2_row2_col3 {\n",
              "  text-align: left;\n",
              "  white-space: pre-wrap;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_16cd2\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_16cd2_level0_col0\" class=\"col_heading level0 col0\" >prompt</th>\n",
              "      <th id=\"T_16cd2_level0_col1\" class=\"col_heading level0 col1\" >choice1</th>\n",
              "      <th id=\"T_16cd2_level0_col2\" class=\"col_heading level0 col2\" >choice2</th>\n",
              "      <th id=\"T_16cd2_level0_col3\" class=\"col_heading level0 col3\" >label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_16cd2_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "      <td id=\"T_16cd2_row0_col0\" class=\"data row0 col0\" >My body cast a shadow over the grass because</td>\n",
              "      <td id=\"T_16cd2_row0_col1\" class=\"data row0 col1\" >The sun was rising.</td>\n",
              "      <td id=\"T_16cd2_row0_col2\" class=\"data row0 col2\" >The grass was cut.</td>\n",
              "      <td id=\"T_16cd2_row0_col3\" class=\"data row0 col3\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_16cd2_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "      <td id=\"T_16cd2_row1_col0\" class=\"data row1 col0\" >The woman tolerated her friend's difficult behavior because</td>\n",
              "      <td id=\"T_16cd2_row1_col1\" class=\"data row1 col1\" >The woman knew her friend was going through a hard time.</td>\n",
              "      <td id=\"T_16cd2_row1_col2\" class=\"data row1 col2\" >The woman felt that her friend took advantage of her kindness.</td>\n",
              "      <td id=\"T_16cd2_row1_col3\" class=\"data row1 col3\" >0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_16cd2_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "      <td id=\"T_16cd2_row2_col0\" class=\"data row2 col0\" >The women met for coffee because</td>\n",
              "      <td id=\"T_16cd2_row2_col1\" class=\"data row2 col1\" >The cafe reopened in a new location.</td>\n",
              "      <td id=\"T_16cd2_row2_col2\" class=\"data row2 col2\" >They wanted to catch up with each other.</td>\n",
              "      <td id=\"T_16cd2_row2_col3\" class=\"data row2 col3\" >1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x79ca6c291bd0>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display_df(df, columns=[\"prompt\", \"choice1\", \"choice2\", \"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHgGqHrKbGNe"
      },
      "source": [
        "# The solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XhJ8a7LsbGNn"
      },
      "outputs": [],
      "source": [
        "examples = [\n",
        "    Example(\n",
        "        prompt=record[\"prompt\"],\n",
        "        completions=(record[\"choice1\"].lower(), record[\"choice2\"].lower()),\n",
        "        prior=None,\n",
        "        end_of_prompt=\" \",  # currently unused by cappr.llama_cpp\n",
        "    )\n",
        "    for record in df.to_dict(\"records\")\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOWsFSuzegqp",
        "outputId": "2e522517-09a2-4bc9-be88-ca321ee4af16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example(prompt='My body cast a shadow over the grass because',\n",
            "        completions=('the sun was rising.', 'the grass was cut.'),\n",
            "        prior=None,\n",
            "        end_of_prompt=' ',\n",
            "        normalize=True)\n"
          ]
        }
      ],
      "source": [
        "pprint(examples[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-28KRa5LrDl"
      },
      "source": [
        "For `llama-cpp` models, CAPPr may be slower than text generation. (If batch inference gets supported by `llama-cpp`, I'll be able to speed up CAPPr.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "03b51814360c4395b345f5328e2e9de0",
            "64c16ac37d0b455d9fc19eb2d43502b8",
            "f4d84be54f5341cf8499af7c4797bdcd",
            "401eaecde4894a039a5a53dd678efe20",
            "b9f880eb7a554a2c9cfecb20b4fb7a5d",
            "57987dd4f8494baea780f24bae4d216c",
            "536e19c6dfa84cffafbe59753c511b01",
            "77ef14313e7547aaad824c3865406a96",
            "7d68932cfed7487d8f5bd1f3e775564d",
            "4bb7bdfebd1d4cb199703e73cc4155cc",
            "4a5cadca6f55487c9e9e274556608dd5"
          ]
        },
        "id": "HB0Rda7rbGNq",
        "outputId": "12e70939-a2f8-423a-fa7d-3da6c987e373"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "03b51814360c4395b345f5328e2e9de0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "conditional log-probs:   0%|          | 0/500 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pred_probs = classify.predict_proba_examples(examples, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vXDHf0uPbGNr"
      },
      "source": [
        "For COPA, the scoring metric is accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVxgmQkwbGNr",
        "outputId": "dd288ffc-6db9-4cd3-fcad-7e2b19d11e96"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.832"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(pred_probs.argmax(axis=1) == df[\"label\"]).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYOh3hpZgkHx"
      },
      "source": [
        "This 4 GB open source model beats OpenAI's `text-curie-001`, which was 80% accurate\n",
        "according to the CAPPr demo\n",
        "[here](https://github.com/kddubey/cappr/blob/main/demos/openai/superglue/copa.ipynb).\n",
        "OpenAI's `gpt-3.5-turbo` is 91% accurate. So we've recovered 0.832/0.91 = 91% of its\n",
        "performance by using CAPPr."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "68daa88f78f5c448099edb3a6d3dee27486a6add8824ae1cbe4c903ef8faec70"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b51814360c4395b345f5328e2e9de0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64c16ac37d0b455d9fc19eb2d43502b8",
              "IPY_MODEL_f4d84be54f5341cf8499af7c4797bdcd",
              "IPY_MODEL_401eaecde4894a039a5a53dd678efe20"
            ],
            "layout": "IPY_MODEL_b9f880eb7a554a2c9cfecb20b4fb7a5d"
          }
        },
        "1aca872f20b14f01b1700613cab4566c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b487626a056424098ec431a53ace749": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_80592af7ea3a454783de4d5ecc830777",
              "IPY_MODEL_8b8def7e1bdb4201aacf26f2ccb396b5",
              "IPY_MODEL_a34db07b4fb14bed8708da1a29329db3"
            ],
            "layout": "IPY_MODEL_1aca872f20b14f01b1700613cab4566c"
          }
        },
        "401eaecde4894a039a5a53dd678efe20": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4bb7bdfebd1d4cb199703e73cc4155cc",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4a5cadca6f55487c9e9e274556608dd5",
            "value": " 500/500 [04:52&lt;00:00,  1.65it/s]"
          }
        },
        "4a5cadca6f55487c9e9e274556608dd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4bb7bdfebd1d4cb199703e73cc4155cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "536e19c6dfa84cffafbe59753c511b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5670c4d9ddee43b69448ba05bf21e964": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57987dd4f8494baea780f24bae4d216c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64c16ac37d0b455d9fc19eb2d43502b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57987dd4f8494baea780f24bae4d216c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_536e19c6dfa84cffafbe59753c511b01",
            "value": "conditional log-probs: 100%"
          }
        },
        "6b45005dfa5f43479b6bf087229f9435": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8b2c58245d4bdabdc9b1c35ff9529a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77ef14313e7547aaad824c3865406a96": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d68932cfed7487d8f5bd1f3e775564d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "80592af7ea3a454783de4d5ecc830777": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cdeb2b3221d5497ba5d3130a796222b2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_c7cef39b81664a1fae26fe407c5f01e5",
            "value": "Sampling: 100%"
          }
        },
        "8b8def7e1bdb4201aacf26f2ccb396b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b45005dfa5f43479b6bf087229f9435",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5670c4d9ddee43b69448ba05bf21e964",
            "value": 500
          }
        },
        "a34db07b4fb14bed8708da1a29329db3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8b2c58245d4bdabdc9b1c35ff9529a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ad74d042c44d45ebaf28cf5cade11f09",
            "value": " 500/500 [02:35&lt;00:00,  3.26it/s]"
          }
        },
        "ad74d042c44d45ebaf28cf5cade11f09": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9f880eb7a554a2c9cfecb20b4fb7a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7cef39b81664a1fae26fe407c5f01e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdeb2b3221d5497ba5d3130a796222b2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4d84be54f5341cf8499af7c4797bdcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77ef14313e7547aaad824c3865406a96",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d68932cfed7487d8f5bd1f3e775564d",
            "value": 500
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
