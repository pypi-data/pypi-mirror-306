# October 31, 2024
In order for the dagrunner package to be able to execute only the nodes that have changed, there must be some caching mechanism. I think that caching mechanism should be implemented somehow here, but then the dagrunner package will actually use it.

My first thought was that the caching mechanism could be to store copies of the configuration files in their original form, perhaps in a .dagpiler folder. So, when dagrunner runs a DAG, its config files would be copied into a folder with the date and time of that run. Then, the next time the DAG is run, it would compare the node in the DAG to that in the cached folder.

But actually, I think that a more straightforward and robust way would be to store a dict of {node_names: node_hashes}. Technically, only the hashes are needed, but including the `node.name` attribute will improve readability. Note that the hashes of a given node would actually be the hash of the subgraph of that node's dependencies. 

This would be achieved through the following steps:
1. Get all ancestors of node N, including node N itself.
2. Extract the subgraph of the ancestors of node N
3. Compute the hash of the subgraph
    - Get all of the edges in the subgraph (tuple of tuples)
    - Hash the tuple of edges 

So, I think this hashing algorithm should be implemented in the `base-dag` package, and the saving and reading of the hashes should be implemented in the `dagpiler` package.