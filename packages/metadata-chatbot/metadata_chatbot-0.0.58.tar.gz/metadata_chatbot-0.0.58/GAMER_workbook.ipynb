{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAMER: Generative Analysis of Metadata Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model uses a multi agent framework on Langraph to retrieve and summarize metadata information based on a user's natural language query. \n",
    "\n",
    "This workflow consists of 6 agents, or nodes, where a decision is made and there is new context provided to either the model or the user. Here are some decisions incorporated into the framework:\n",
    "1. To best answer the query, does the entire database need to be queried, or the vector index?\n",
    "- Input: `x (query)`\n",
    "- Decides best data to query against\n",
    "- Output: `entire_database, vector_embeddings`\n",
    "2. If querying against the vector embeddings, does the index need to be filtered further with metdata tags, to improve optimization of retrieval?\n",
    "- Input: `x (query)`\n",
    "- Decides whether database can be further filtered by applying a MongoDB query\n",
    "- Output: `MongoDB query, None`\n",
    "3. Are the documents retrieved during retrieval relevant to the question?\n",
    "- Input: `x (query)`\n",
    "- Decides whether document should be kept or tossed during summarization\n",
    "- Output: `yes, no`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Graph workflow](C:\\Users\\sreya.kumar\\Documents\\GitHub\\metadata-chatbot\\graph_workflow.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronous calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: metadata-chatbot\n",
      "Version: 0.0.54\n",
      "Summary: Generated from aind-library-template\n",
      "Home-page: \n",
      "Author: Allen Institute for Neural Dynamics\n",
      "Author-email: \n",
      "License: MIT\n",
      "Location: C:\\Users\\sreya.kumar\\Documents\\GitHub\\metadata-chatbot\\venv\\Lib\\site-packages\n",
      "Requires: aind-data-access-api, boto3, fastapi, langchain, langchain-aws, langchain-community, langchain-core, langgraph, motor, nest-asyncio, pymongo, pytest, sshtunnel, uvicorn\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show metadata_chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The refractive index of the chamber immersion medium used in the experiment SmartSPIM_675387_2023-05-23_23-05-56 was 1.5207 (Cargille Oil 1.5200).\n"
     ]
    }
   ],
   "source": [
    "from metadata_chatbot.agents.GAMER import GAMER\n",
    "query = \"What was the refractive index of the chamber immersion medium used in this experiment SmartSPIM_675387_2023-05-23_23-05-56\"\n",
    "\n",
    "model = GAMER()\n",
    "result = model.invoke(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sreya.kumar\\Documents\\GitHub\\metadata-chatbot\\venv\\Lib\\site-packages\\metadata_chatbot\\agents\\async_workflow.py:112: LangChainDeprecationWarning: The method `BaseRetriever.aget_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~ainvoke` instead.\n",
      "  documents = await retriever.aget_relevant_documents(query = query, query_filter = filter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context, here are the procedures performed on specimen 662616 and their start/end dates:\n",
      "\n",
      "Subject procedures:\n",
      "1. Surgery on 2023-01-25 with virus injections\n",
      "2. Surgery on 2023-01-25 with virus injection\n",
      "\n",
      "Specimen procedures:\n",
      "1. Fixation (SHIELD OFF) from 2023-02-10 to 2023-02-12\n",
      "2. Fixation (SHIELD ON) from 2023-02-12 to 2023-02-13\n",
      "3. Delipidation (24h Delipidation) from 2023-02-15 to 2023-02-16  \n",
      "4. Delipidation (Active Delipidation) from 2023-02-16 to 2023-02-18\n",
      "5. Refractive index matching (50% EasyIndex) from 2023-02-19 to 2023-02-20\n",
      "6. Refractive index matching (100% EasyIndex) from 2023-02-20 to 2023-02-21\n",
      "\n",
      "Imaging procedure:\n",
      "1. SmartSPIM imaging session from 2023-03-06T17:47:13 to 2023-03-06T22:59:16\n"
     ]
    }
   ],
   "source": [
    "from metadata_chatbot.agents.GAMER import GAMER\n",
    "llm = GAMER()\n",
    "query = \"Can you list all the procedures performed on the specimen, including their start and end dates? in SmartSPIM_662616_2023-03-06_17-47-13\"\n",
    "\n",
    "result = await llm.ainvoke(query)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
